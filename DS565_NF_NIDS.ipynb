{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**DSCI 565: Semester Project**\n",
        "\n",
        "Reference Paper:\n",
        "\n",
        "FlowTransformer: A Transformer Framework for Flow-based Network Intrusion Detection Systems\n",
        "\n",
        "Dataset:\n",
        "\n",
        "Towards a Standard Feature Set for Network Intrusion Detection System Datasets (NetFlow-v2)\n",
        "\n",
        "https://staff.itee.uq.edu.au/marius/NIDS_datasets/\n",
        "\n",
        "NF-UNSW-NB15-v2, NF-CSE-CIC-IDS2018-v2\n",
        "\n",
        "Keyword: REQ"
      ],
      "metadata": {
        "id": "0v920que-00p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaoMzTnmHmWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50e1f75f-246c-42c8-edf7-0e839a7c0059"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, sys\n",
        "# framework library\n",
        "# https://github.com/liamdm/FlowTransformer\n",
        "path = \"/content/drive/MyDrive/FlowTransformer/\" # /FlowTransformer/ folder\n",
        "\n",
        "if path not in sys.path:\n",
        "    sys.path.append(path)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from typing import Tuple, List, Dict, Any, Optional\n",
        "from enum import Enum\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "try:\n",
        "    from tensorflow._api.v2.v2 import keras\n",
        "except ImportError:\n",
        "    from tensorflow import keras\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras.layers as layers\n",
        "from keras.layers import Embedding, Dense, Layer, MultiHeadAttention, Dropout, LayerNormalization, Conv1D, Concatenate, Reshape, Flatten, Lambda, GlobalAveragePooling1D\n",
        "\n",
        "# FlowTransformer framework\n",
        "from framework.base_preprocessing import BasePreProcessing\n",
        "from framework.enumerations import CategoricalFormat\n",
        "from framework.base_input_encoding import BaseInputEncoding\n",
        "from framework.base_classification_head import BaseClassificationHead\n",
        "from framework.base_sequential import BaseSequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = path + \"data/\"\n",
        "feature = \"NetFlow_v2_Features.csv\"\n",
        "datasets = [\"NF-CSE-CIC-IDS2018-v2/NF-CSE-CIC-IDS2018-v2.csv\", \"NF-UNSW-NB15-v2/NF-UNSW-NB15-v2.csv\"]\n",
        "\n",
        "!wc -l drive/MyDrive/FlowTransformer/data/NetFlow_v2_Features.csv  # /FlowTransformer/ folder\n",
        "!wc -l drive/MyDrive/FlowTransformer/data/NF-CSE-CIC-IDS2018-v2/NF-CSE-CIC-IDS2018-v2.csv  # /FlowTransformer/ folder\n",
        "!wc -l drive/MyDrive/FlowTransformer/data/NF-UNSW-NB15-v2/NF-UNSW-NB15-v2.csv  # /FlowTransformer/ folder"
      ],
      "metadata": {
        "id": "zmOVSlqusz9j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "716db224-9658-4e95-87b7-087edb957d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44 drive/MyDrive/FlowTransformer/data/NetFlow_v2_Features.csv\n",
            "18893709 drive/MyDrive/FlowTransformer/data/NF-CSE-CIC-IDS2018-v2/NF-CSE-CIC-IDS2018-v2.csv\n",
            "2390276 drive/MyDrive/FlowTransformer/data/NF-UNSW-NB15-v2/NF-UNSW-NB15-v2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementation**"
      ],
      "metadata": {
        "id": "8Y6y5_Re95Iz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NetFlow Collector & Pre-processing"
      ],
      "metadata": {
        "id": "AExZFUoJW8xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NetFlow Collector\n",
        "# REQ\n",
        "\n",
        "# Pre-precessing\n",
        "# https://github.com/liamdm/FlowTransformer/blob/master/implementations/pre_processings.py\n",
        "class StandardPreProcessing(BasePreProcessing):\n",
        "    def __init__(self, n_categorical_levels: int, clip_numerical_values:bool=False):\n",
        "        super().__init__()\n",
        "        self.n_categorical_levels:int = n_categorical_levels\n",
        "        self.clip_numerical_values:bool = clip_numerical_values\n",
        "        self.min_range = {}\n",
        "        self.encoded_levels = {}\n",
        "\n",
        "    @property\n",
        "    def name(self) -> str:\n",
        "        return \"Standard Preprocessing\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self) -> dict:\n",
        "        return {\n",
        "            \"n_categorical_levels\": self.n_categorical_levels,\n",
        "            \"clip_numerical_values\": self.clip_numerical_values\n",
        "        }\n",
        "\n",
        "    def fit_numerical(self, column_name: str, values: np.array):\n",
        "\n",
        "        v0 = np.min(values)\n",
        "        v1 = np.max(values)\n",
        "        r = v1 - v0\n",
        "\n",
        "        self.min_range[column_name] = (v0, r)\n",
        "\n",
        "    def transform_numerical(self, column_name: str, values: np.array):\n",
        "        col_min, col_range = self.min_range[column_name]\n",
        "\n",
        "        if col_range == 0:\n",
        "            return np.zeros_like(values, dtype=\"float32\")\n",
        "\n",
        "        # center on zero\n",
        "        values -= col_min\n",
        "\n",
        "        # apply a logarithm\n",
        "        col_values = np.log(values + 1)\n",
        "\n",
        "        # scale max to 1\n",
        "        col_values *= 1. / np.log(col_range + 1)\n",
        "\n",
        "        if self.clip_numerical_values:\n",
        "            col_values = np.clip(col_values, 0., 1.)\n",
        "\n",
        "        return col_values\n",
        "\n",
        "    def fit_categorical(self, column_name: str, values: np.array):\n",
        "        levels, level_counts = np.unique(values, return_counts=True)\n",
        "        sorted_levels = list(sorted(zip(levels, level_counts), key=lambda x: x[1], reverse=True))\n",
        "        self.encoded_levels[column_name] = [s[0] for s in sorted_levels[:self.n_categorical_levels]]\n",
        "\n",
        "\n",
        "    def transform_categorical(self, column_name:str, values: np.array, expected_categorical_format: CategoricalFormat):\n",
        "        encoded_levels = self.encoded_levels[column_name]\n",
        "        print(f\"Encoding the {len(encoded_levels)} levels for {column_name}\")\n",
        "\n",
        "        result_values = np.ones(len(values), dtype=\"uint32\")\n",
        "        for level_i, level in enumerate(encoded_levels):\n",
        "            level_mask = values == level\n",
        "\n",
        "            # we use +1 here, as 0 = previously unseen, and 1 to (n + 1) are the encoded levels\n",
        "            result_values[level_mask] = level_i + 1\n",
        "\n",
        "        if expected_categorical_format == CategoricalFormat.Integers:\n",
        "            return result_values\n",
        "\n",
        "        v = pd.get_dummies(result_values, prefix=column_name)\n",
        "        return v"
      ],
      "metadata": {
        "id": "dWX1zO9YW-lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FlowTransformer Framework"
      ],
      "metadata": {
        "id": "iGZ6bAcYXAEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Encoder\n",
        "# ref: https://github.com/liamdm/FlowTransformer/blob/master/implementations/input_encodings.py\n",
        "class NoInputEncoder(BaseInputEncoding):\n",
        "    def apply(self, X, prefix:str=None):\n",
        "\n",
        "        numerical_feature_inputs = X[:self.model_input_specification.n_numeric_features]\n",
        "        categorical_feature_inputs = X[self.model_input_specification.n_numeric_features:]\n",
        "\n",
        "        if self.model_input_specification.categorical_format == CategoricalFormat.Integers:\n",
        "            warnings.warn(\"It doesn't make sense to be using integer based inputs without encoding!\")\n",
        "            categorical_feature_inputs = [Lambda(lambda x: tf.cast(x, tf.float32))(c) for c in categorical_feature_inputs]\n",
        "\n",
        "        concat = Concatenate()(numerical_feature_inputs + categorical_feature_inputs)\n",
        "\n",
        "        return concat\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "        return \"No Input Encoding\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self):\n",
        "        return {}\n",
        "\n",
        "    @property\n",
        "    def required_input_format(self) -> CategoricalFormat:\n",
        "        return CategoricalFormat.OneHot\n",
        "\n",
        "class EmbedLayerType(Enum):\n",
        "    Dense = 0,\n",
        "    Lookup = 1,\n",
        "    Projection = 2\n",
        "\n",
        "class RecordLevelEmbed(BaseInputEncoding):\n",
        "    def __init__(self, embed_dimension: int, project:bool = False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed_dimension: int = embed_dimension\n",
        "        self.project: bool = project\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "        if self.project:\n",
        "            return \"Record Level Projection\"\n",
        "        return \"Record Level Embedding\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self):\n",
        "        return {\n",
        "            \"dimensions_per_feature\": self.embed_dimension\n",
        "        }\n",
        "\n",
        "    def apply(self, X:List[keras.Input], prefix: str = None):\n",
        "        if prefix is None:\n",
        "            prefix = \"\"\n",
        "\n",
        "        assert self.model_input_specification.categorical_format == CategoricalFormat.OneHot\n",
        "\n",
        "        x = Concatenate(name=f\"{prefix}feature_concat\", axis=-1)(X)\n",
        "        x = Dense(self.embed_dimension, activation=\"linear\", use_bias=not self.project, name=f\"{prefix}embed\")(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def required_input_format(self) -> CategoricalFormat:\n",
        "        return CategoricalFormat.OneHot\n",
        "\n",
        "class CategoricalFeatureEmbed(BaseInputEncoding):\n",
        "    def __init__(self, embed_layer_type: EmbedLayerType, dimensions_per_feature: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dimensions_per_feature: int = dimensions_per_feature\n",
        "        self.embed_layer_type: EmbedLayerType = embed_layer_type\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "        if self.embed_layer_type == EmbedLayerType.Dense:\n",
        "            return f\"Categorical Feature Embed - Dense\"\n",
        "        elif self.embed_layer_type == EmbedLayerType.Lookup:\n",
        "            return f\"Categorical Feature Embed - Lookup\"\n",
        "        elif self.embed_layer_type == EmbedLayerType.Projection:\n",
        "            return f\"Categorical Feature Embed - Projection\"\n",
        "        raise RuntimeError()\n",
        "\n",
        "    @property\n",
        "    def parameters(self):\n",
        "        return {\n",
        "            \"dimensions_per_feature\": self.dimensions_per_feature\n",
        "        }\n",
        "\n",
        "    def apply(self, X:List[keras.Input], prefix:str=None):\n",
        "        if prefix is None:\n",
        "            prefix = \"\"\n",
        "\n",
        "        if self.model_input_specification is None:\n",
        "            raise Exception(\"Please call build() before calling apply!\")\n",
        "\n",
        "        numerical_feature_inputs = X[:self.model_input_specification.n_numeric_features]\n",
        "        categorical_feature_inputs = X[self.model_input_specification.n_numeric_features:]\n",
        "\n",
        "        #print(len(numerical_feature_inputs), len(categorical_feature_inputs))\n",
        "        #print(len(self.model_input_specification.categorical_feature_names), self.model_input_specification.categorical_feature_names)\n",
        "\n",
        "        collected_numeric = Concatenate(name=f\"{prefix}concat_numeric\")(numerical_feature_inputs)\n",
        "\n",
        "        collected_categorical = []\n",
        "        for categorical_field_i, categorical_field_name in enumerate(self.model_input_specification.categorical_feature_names):\n",
        "            cat_field_x = categorical_feature_inputs[categorical_field_i]\n",
        "            if self.embed_layer_type != EmbedLayerType.Lookup:\n",
        "                assert self.model_input_specification.categorical_format == CategoricalFormat.OneHot\n",
        "\n",
        "                x = Dense(self.dimensions_per_feature,\n",
        "                          activation=\"linear\",\n",
        "                          use_bias=(self.embed_layer_type == EmbedLayerType.Dense),\n",
        "                          name=f\"{prefix}embed_{categorical_field_name.replace('/', '')}\")(cat_field_x)\n",
        "                collected_categorical.append(x)\n",
        "\n",
        "            elif self.embed_layer_type == EmbedLayerType.Lookup:\n",
        "                assert self.model_input_specification.categorical_format == CategoricalFormat.Integers\n",
        "\n",
        "                # reshape the sequence to a flat array\n",
        "                x = cat_field_x\n",
        "                x = Embedding(input_dim=self.model_input_specification.levels_per_categorical_feature[categorical_field_i] + 1, output_dim=self.dimensions_per_feature, input_length=self.sequence_length)(x)\n",
        "                x = Reshape((self.sequence_length, self.dimensions_per_feature), name=f\"{prefix}expand_{categorical_field_name}\")(x)\n",
        "\n",
        "                collected_categorical.append(x)\n",
        "        collected_categorical = Concatenate(name=f\"{prefix}concat_categorical\")(collected_categorical)\n",
        "\n",
        "        collected = Concatenate()([collected_numeric, collected_categorical])\n",
        "\n",
        "        return collected\n",
        "\n",
        "    @property\n",
        "    def required_input_format(self) -> CategoricalFormat:\n",
        "        return CategoricalFormat.Integers if self.embed_layer_type == EmbedLayerType.Lookup else CategoricalFormat.OneHot\n",
        "\n",
        "# Transformer Models\n",
        "\n",
        "# Decoder Block\n",
        "# ref: https://github.com/liamdm/FlowTransformer/blob/master/implementations/transformers/basic/decoder_block.py\n",
        "class TransformerDecoderBlock(Layer):\n",
        "    def __init__(self, input_dimension:int, inner_dimension:int, num_heads:int, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.input_dimension = input_dimension\n",
        "        self.inner_dimension = inner_dimension\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=input_dimension)\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(inner_dimension, activation='relu'),\n",
        "            Dense(input_dimension)\n",
        "        ])\n",
        "        self.dropout2 = Dropout(dropout_rate)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    # noinspection PyMethodOverriding\n",
        "    # SIAN\n",
        "    def call(self, inputs, training=True, mask=None):\n",
        "        # inputs = (target_seq, enc_output)\n",
        "        target_seq = inputs\n",
        "        enc_output = inputs\n",
        "\n",
        "        # self attention of target_seq\n",
        "        attn_output = self.mha(target_seq, target_seq)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = target_seq + attn_output\n",
        "        out1 = self.layernorm1(out1)\n",
        "\n",
        "        # multi-head attention with encoder output as the key and value, and target_seq as the query\n",
        "        attn_output = self.mha(out1, enc_output)\n",
        "        attn_output = self.dropout2(attn_output, training=training)\n",
        "        out2 = out1 + attn_output\n",
        "        out2 = self.layernorm2(out2)\n",
        "\n",
        "        # feed forward network\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out3 = out2 + ffn_output\n",
        "        out3 = self.layernorm2(out3)\n",
        "\n",
        "        return out3\n",
        "\n",
        "# Encoder Block\n",
        "# ref: https://github.com/liamdm/FlowTransformer/blob/master/implementations/transformers/basic/encoder_block.py\n",
        "class GPT3Attention(layers.Layer):\n",
        "    def __init__(self, n_heads, d_model, dropout_rate=0.1):\n",
        "        super(GPT3Attention, self).__init__()\n",
        "        self.n_heads = n_heads\n",
        "        self.d_model = d_model\n",
        "        self.depth = d_model // n_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.n_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # noinspection PyMethodOverriding\n",
        "    def call(self, q, k, v, mask=None):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        # Scaled Dot-Product Attention\n",
        "        scaled_attention_logits = tf.matmul(q, k, transpose_b=True)\n",
        "        scaled_attention_logits = scaled_attention_logits / tf.math.sqrt(tf.cast(self.depth, tf.float32))\n",
        "\n",
        "        if mask is not None:\n",
        "            scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "        attention_weights = self.dropout(attention_weights)\n",
        "\n",
        "        output = tf.matmul(attention_weights, v)\n",
        "        output = tf.transpose(output, perm=[0, 2, 1, 3])\n",
        "        output = tf.reshape(output, (batch_size, -1, self.d_model))\n",
        "\n",
        "        output = self.dense(output)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "class MultiHeadAttentionImplementation:\n",
        "    Keras = 0,\n",
        "    GPT3 = 1\n",
        "\n",
        "class TransformerEncoderBlock(layers.Layer):\n",
        "    def __init__(self, input_dimension:int, inner_dimension:int, num_heads:int, dropout_rate=0.1, use_conv:bool=False, prefix:str=None, attn_implementation:MultiHeadAttentionImplementation = MultiHeadAttentionImplementation.Keras):\n",
        "\n",
        "        if prefix is None:\n",
        "            prefix = \"\"\n",
        "\n",
        "        super().__init__(name=f\"{prefix}transformer_encoder\")\n",
        "\n",
        "        if inner_dimension < input_dimension:\n",
        "            warnings.warn(f\"Typically inner_dimension should be greater than or equal to the input_dimension!\")\n",
        "\n",
        "        self.attn_implementation = attn_implementation\n",
        "\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.attention = \\\n",
        "            layers.MultiHeadAttention(num_heads=num_heads, key_dim=inner_dimension, name=f\"{prefix}multi_head_attn\") \\\n",
        "                if attn_implementation == MultiHeadAttentionImplementation.Keras else\\\n",
        "                GPT3Attention(num_heads, inner_dimension, dropout_rate=0.0)\n",
        "\n",
        "        layer_norm = 1e-6\n",
        "\n",
        "        self.attention_dropout = layers.Dropout(dropout_rate, name=f\"{prefix}attention_dropout\")\n",
        "        self.attention_layer_norm = layers.LayerNormalization(epsilon=layer_norm, name=f\"{prefix}attention_layer_norm\")\n",
        "\n",
        "        self.feed_forward_0 = Conv1D(filters=inner_dimension, kernel_size=1, activation=\"relu\", name=f\"{prefix}feed_forward_0\") \\\n",
        "            if use_conv else Dense(inner_dimension, activation=\"relu\", name=f\"{prefix}feed_forward_0\")\n",
        "        self.feed_forward_1 = Conv1D(filters=input_dimension, kernel_size=1, activation=\"relu\", name=f\"{prefix}feed_forward_1\") \\\n",
        "            if use_conv else Dense(input_dimension, activation=\"relu\", name=f\"{prefix}feed_forward_1\")\n",
        "\n",
        "        self.feed_forward_dropout = layers.Dropout(dropout_rate, name=f\"{prefix}feed_forward_dropout\")\n",
        "        self.feed_forward_layer_norm = layers.LayerNormalization(epsilon=layer_norm, name=f\"{prefix}feed_forward_layer_norm\")\n",
        "\n",
        "    # noinspection PyMethodOverriding\n",
        "    # SIAN\n",
        "    def call(self, inputs, training=True, mask=None):\n",
        "        x = inputs\n",
        "        x = self.attention(x, x) if self.attn_implementation == MultiHeadAttentionImplementation.Keras else self.attention(x, x, x, mask)\n",
        "\n",
        "        attention_output = self.attention_dropout(x, training=training) if self.dropout_rate > 0 else x\n",
        "\n",
        "        x = inputs + attention_output\n",
        "        x = self.attention_layer_norm(x)\n",
        "        x = self.feed_forward_0(x)\n",
        "        x = self.feed_forward_1(x)\n",
        "        x = self.feed_forward_dropout(x, training=training) if self.dropout_rate > 0 else x\n",
        "        feed_forward_output = x\n",
        "\n",
        "        return self.feed_forward_layer_norm(attention_output + feed_forward_output)\n",
        "\n",
        "# Basic Transformers\n",
        "# ref: https://github.com/liamdm/FlowTransformer/blob/master/implementations/transformers/basic_transformers.py\n",
        "class BasicTransformer(BaseSequential):\n",
        "\n",
        "    @property\n",
        "    def name(self) -> str:\n",
        "        if self.use_conv:\n",
        "            return f\"Basic Conv Transformer\" + (\" Decoder\" if self.is_decoder else \"\")\n",
        "        else:\n",
        "            return f\"Basic Dense Transformer\" + (\" Decoder\" if self.is_decoder else \"\")\n",
        "\n",
        "    @property\n",
        "    def parameters(self) -> dict:\n",
        "        return {\n",
        "            \"n_layers\": self.n_layers,\n",
        "            \"internal_size\": self.internal_size,\n",
        "            \"use_conv\": self.use_conv,\n",
        "            \"n_heads\": self.n_heads,\n",
        "            \"dropout_rate\": self.dropout_rate,\n",
        "            \"head_size\": self.internal_size\n",
        "        }\n",
        "\n",
        "    def __init__(self, n_layers:int, internal_size:int, n_heads:int, use_conv:bool=False, dropout_rate:float=0.1, is_decoder=False):\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.internal_size = internal_size\n",
        "        self.use_conv = use_conv\n",
        "        self.n_heads = n_heads\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.is_decoder = is_decoder\n",
        "\n",
        "    def apply(self, X, prefix: str = None):\n",
        "        #window_size = self.sequence_length\n",
        "        real_size = X.shape[-1]\n",
        "\n",
        "        m_x = X\n",
        "\n",
        "        for layer_i in range(self.n_layers):\n",
        "            if self.is_decoder:\n",
        "                if self.use_conv:\n",
        "                    raise NotImplementedError()\n",
        "                m_x = TransformerDecoderBlock(real_size, self.internal_size, self.n_heads, dropout_rate=self.dropout_rate)(m_x)\n",
        "            else:\n",
        "                m_x = TransformerEncoderBlock(real_size, self.internal_size, self.n_heads, dropout_rate=self.dropout_rate, use_conv=self.use_conv, prefix=f\"{prefix}block_{layer_i}_\")(m_x)\n",
        "\n",
        "        return m_x\n",
        "\n",
        "# Named Transformers\n",
        "# ref: https://github.com/liamdm/FlowTransformer/blob/master/implementations/transformers/named_transformers.py\n",
        "class GPTSmallTransformer(BaseSequential):\n",
        "\n",
        "    @property\n",
        "    def name(self) -> str:\n",
        "        return \"GPT Model\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self) -> dict:\n",
        "        return {\n",
        "            \"n_layers\": self.n_layers,\n",
        "            \"internal_size\": self.internal_size,\n",
        "            \"n_heads\": self.n_heads,\n",
        "            \"dropout_rate\": self.dropout_rate,\n",
        "            \"head_size\": self.head_size\n",
        "        }\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.n_layers = 12\n",
        "        self.internal_size = 768\n",
        "        self.n_heads = 12\n",
        "        self.head_size = self.internal_size / self.n_heads\n",
        "        self.dropout_rate = 0.02\n",
        "        self.is_decoder = True\n",
        "\n",
        "    def apply(self, X, prefix: str = None):\n",
        "        #window_size = self.sequence_length\n",
        "        real_size = X.shape[-1]\n",
        "\n",
        "        m_x = X\n",
        "\n",
        "        for layer_i in range(self.n_layers):\n",
        "            m_x = TransformerDecoderBlock(real_size, self.internal_size, self.n_heads, dropout_rate=self.dropout_rate)(m_x)\n",
        "\n",
        "        return m_x\n",
        "\n",
        "\n",
        "class BERTSmallTransformer(BaseSequential):\n",
        "\n",
        "    @property\n",
        "    def name(self) -> str:\n",
        "        return \"BERT Model\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self) -> dict:\n",
        "        return {\n",
        "            \"n_layers\": self.n_layers,\n",
        "            \"internal_size\": self.internal_size,\n",
        "            \"n_heads\": self.n_heads,\n",
        "            \"dropout_rate\": self.dropout_rate,\n",
        "            \"head_size\": self.head_size\n",
        "        }\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.n_layers = 12\n",
        "        self.internal_size = 768\n",
        "        self.n_heads = 12\n",
        "        self.head_size = self.internal_size / self.n_heads\n",
        "        self.dropout_rate = 0.02\n",
        "        self.is_decoder = False\n",
        "\n",
        "    def apply(self, X, prefix: str = None):\n",
        "        #window_size = self.sequence_length\n",
        "        real_size = X.shape[-1]\n",
        "\n",
        "        m_x = X\n",
        "\n",
        "        for layer_i in range(self.n_layers):\n",
        "            m_x = TransformerEncoderBlock(real_size, self.internal_size, self.n_heads, dropout_rate=self.dropout_rate, prefix=f\"block_{layer_i}_\")(m_x)\n",
        "\n",
        "        return m_x\n",
        "\n",
        "# Classficiation Head\n",
        "# ref: https://github.com/liamdm/FlowTransformer/blob/master/implementations/classification_heads.py\n",
        "class FlattenClassificationHead(BaseClassificationHead):\n",
        "    def apply(self, X, prefix: str = None):\n",
        "        if prefix is None:\n",
        "            prefix = \"\"\n",
        "        x = Flatten(name=f\"{prefix}flatten\")(X)\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def name(self) -> str:\n",
        "        return \"Flatten\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self) -> dict:\n",
        "        return {}\n",
        "\n",
        "\n",
        "class FeaturewiseEmbedding(BaseClassificationHead):\n",
        "    def __init__(self, project:bool=False):\n",
        "        super().__init__()\n",
        "        self.project: bool = project\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "        if self.project:\n",
        "            return f\"Featurewise Embed - Projection\"\n",
        "        else:\n",
        "            return f\"Featurewise Embed - Dense\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self):\n",
        "        return {}\n",
        "\n",
        "\n",
        "    def apply(self, X, prefix:str=None):\n",
        "        if prefix is None:\n",
        "            prefix = \"\"\n",
        "\n",
        "        if self.model_input_specification is None:\n",
        "            raise Exception(\"Please call build() before calling apply!\")\n",
        "\n",
        "        x = Dense(1,\n",
        "                  activation=\"linear\",\n",
        "                  use_bias=(not self.project),\n",
        "                  name=f\"{prefix}featurewise_embed\")(X)\n",
        "\n",
        "        x = Flatten()(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class GlobalAveragePoolingClassificationHead(BaseClassificationHead):\n",
        "    def apply(self, X, prefix: str = None):\n",
        "        if prefix is None:\n",
        "            prefix = \"\"\n",
        "        return GlobalAveragePooling1D(name=f\"{prefix}global_avg_pooling_1d\")(X)\n",
        "\n",
        "    @property\n",
        "    def name(self) -> str:\n",
        "        return \"Global Average Pooling\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self) -> dict:\n",
        "        return {}\n",
        "\n",
        "\n",
        "class LastTokenClassificationHead(BaseClassificationHead):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def apply(self, X, prefix: str = None):\n",
        "        if prefix is None:\n",
        "            prefix = \"\"\n",
        "\n",
        "        x = Lambda(lambda x: x[..., -1, :], name=f\"{prefix}slice_last\")(X)\n",
        "        #x = Flatten(name=f\"{prefix}flatten_last\")(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def name(self) -> str:\n",
        "        return \"Last Token\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self) -> dict:\n",
        "        return {}\n",
        "\n",
        "\n",
        "class CLSTokenClassificationHead(LastTokenClassificationHead):\n",
        "\n",
        "\n",
        "    @property\n",
        "    def name(self) -> str:\n",
        "        return \"CLS Token\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self) -> dict:\n",
        "        return {}\n",
        "\n",
        "    def apply_before_transformer(self, X, prefix: str = None):\n",
        "        if prefix is None:\n",
        "            prefix = \"\"\n",
        "\n",
        "        window_size = self.sequence_length\n",
        "\n",
        "        x = X\n",
        "        batch_size = tf.shape(x)[0]\n",
        "        flow_size = tf.shape(x)[2]\n",
        "\n",
        "        cls_token_horizontal_single = np.zeros((window_size + 1,))\n",
        "        cls_token_horizontal_single[-1] = 1.\n",
        "        cls_token_horizontal_single = tf.convert_to_tensor(cls_token_horizontal_single, dtype=tf.float32)\n",
        "\n",
        "        cls_token_horizontal = tf.ones((batch_size, window_size + 1,), dtype=tf.float32)\n",
        "        cls_token_horizontal = tf.multiply(cls_token_horizontal, cls_token_horizontal_single)\n",
        "        cls_token_horizontal = tf.expand_dims(cls_token_horizontal, axis=-1)\n",
        "\n",
        "        cls_token_vertical = tf.zeros((batch_size, 1, flow_size,), dtype=tf.float32)\n",
        "\n",
        "        x = Concatenate(axis=-2, name=f'{prefix}cls_vertical')([x, cls_token_vertical])\n",
        "        x = Concatenate(axis=-1, name=f'{prefix}cls_horizontal')([x, cls_token_horizontal])\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "m8-2xeP8XGiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Demonstration**\n",
        "\n",
        "ref:\n",
        "\n",
        "https://github.com/liamdm/FlowTransformer/blob/master/demonstration.ipynb\n",
        "\n",
        "https://github.com/liamdm/FlowTransformer/blob/master/FlowTransformer_demo.ipynb"
      ],
      "metadata": {
        "id": "xIZu030l-FA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demonstration_folder = \"demonstration\"\n",
        "\n",
        "if not os.path.exists(demonstration_folder):\n",
        "    os.mkdir(demonstration_folder)\n",
        "\n",
        "from framework.dataset_specification import DatasetSpecification\n",
        "flow_format = DatasetSpecification(\n",
        "        include_fields=['NUM_PKTS_UP_TO_128_BYTES', 'SRC_TO_DST_SECOND_BYTES', 'OUT_PKTS', 'OUT_BYTES', 'NUM_PKTS_128_TO_256_BYTES', 'DST_TO_SRC_AVG_THROUGHPUT', 'DURATION_IN', 'L4_SRC_PORT', 'ICMP_TYPE', 'PROTOCOL', 'SERVER_TCP_FLAGS', 'IN_PKTS', 'NUM_PKTS_512_TO_1024_BYTES', 'CLIENT_TCP_FLAGS', 'TCP_WIN_MAX_IN', 'NUM_PKTS_256_TO_512_BYTES', 'SHORTEST_FLOW_PKT', 'MIN_IP_PKT_LEN', 'LONGEST_FLOW_PKT', 'L4_DST_PORT', 'MIN_TTL', 'DST_TO_SRC_SECOND_BYTES', 'NUM_PKTS_1024_TO_1514_BYTES', 'DURATION_OUT', 'FLOW_DURATION_MILLISECONDS', 'TCP_FLAGS', 'MAX_TTL', 'SRC_TO_DST_AVG_THROUGHPUT', 'ICMP_IPV4_TYPE', 'MAX_IP_PKT_LEN', 'RETRANSMITTED_OUT_BYTES', 'IN_BYTES', 'RETRANSMITTED_IN_BYTES', 'TCP_WIN_MAX_OUT', 'L7_PROTO', 'RETRANSMITTED_OUT_PKTS', 'RETRANSMITTED_IN_PKTS'],\n",
        "        categorical_fields=['CLIENT_TCP_FLAGS', 'L4_SRC_PORT', 'TCP_FLAGS', 'ICMP_IPV4_TYPE', 'ICMP_TYPE', 'PROTOCOL', 'SERVER_TCP_FLAGS', 'L4_DST_PORT', 'L7_PROTO'],\n",
        "        class_column=\"Attack\",\n",
        "        benign_label=\"Benign\"\n",
        "    )\n",
        "\n",
        "from framework.flow_transformer_parameters import FlowTransformerParameters\n",
        "from framework.flow_transformer import FlowTransformer\n",
        "\n",
        "pre_processing = StandardPreProcessing(n_categorical_levels=32)\n",
        "encoding = RecordLevelEmbed(64)\n",
        "transformer = BasicTransformer(n_layers=2, internal_size=128, n_heads=2)\n",
        "classification_head = LastTokenClassificationHead()\n",
        "\n",
        "# Define the transformer\n",
        "ft = FlowTransformer(pre_processing=pre_processing,\n",
        "                     input_encoding=encoding,\n",
        "                     sequential_model=transformer,\n",
        "                     classification_head=classification_head,\n",
        "                     params=FlowTransformerParameters(window_size=8, mlp_layer_sizes=[128], mlp_dropout=0.1))\n",
        "\n",
        "from framework.enumerations import EvaluationDatasetSampling\n",
        "from IPython.display import display\n",
        "\n",
        "# SIAN\n",
        "df = ft.load_dataset(\"UNSW-NB15\",\n",
        "                    data_path+datasets[1],\n",
        "                    specification=flow_format,\n",
        "                    evaluation_dataset_sampling=EvaluationDatasetSampling.LastRows,\n",
        "                    evaluation_percent=0.1,\n",
        "                    cache_path=demonstration_folder)\n",
        "\n",
        "display(df.iloc[:500])"
      ],
      "metadata": {
        "id": "DMoRLR7i-VFI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d014017-95e5-40ae-8f3e-46799ca9028d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cache file path: demonstration/UNSW-NB15_0_QdLmZHuh8yOmlGcKBEkf7hepImY0_5EjmvToFWKee8t20u0dFpVzNu4s0.feather\n",
            "Attempting to read dataset from path /content/drive/MyDrive/FlowTransformer/data/NF-UNSW-NB15-v2/NF-UNSW-NB15-v2.csv...\n",
            "Set y to = Attack\n",
            "Converting numerical columns to floats, and removing out of range values...\n",
            "Applying pre-processing to numerical values\n",
            "[Numerical 1 / 28] Processing numerical column IN_BYTES...\n",
            "[Numerical 2 / 28] Processing numerical column DST_TO_SRC_SECOND_BYTES...\n",
            "[Numerical 3 / 28] Processing numerical column LONGEST_FLOW_PKT...\n",
            "[Numerical 4 / 28] Processing numerical column FLOW_DURATION_MILLISECONDS...\n",
            "[Numerical 5 / 28] Processing numerical column TCP_WIN_MAX_IN...\n",
            "[Numerical 6 / 28] Processing numerical column SHORTEST_FLOW_PKT...\n",
            "[Numerical 7 / 28] Processing numerical column IN_PKTS...\n",
            "[Numerical 8 / 28] Processing numerical column NUM_PKTS_1024_TO_1514_BYTES...\n",
            "[Numerical 9 / 28] Processing numerical column RETRANSMITTED_IN_PKTS...\n",
            "[Numerical 10 / 28] Processing numerical column SRC_TO_DST_SECOND_BYTES...\n",
            "[Numerical 11 / 28] Processing numerical column RETRANSMITTED_OUT_PKTS...\n",
            "[Numerical 12 / 28] Processing numerical column OUT_PKTS...\n",
            "[Numerical 13 / 28] Processing numerical column NUM_PKTS_512_TO_1024_BYTES...\n",
            "[Numerical 14 / 28] Processing numerical column SRC_TO_DST_AVG_THROUGHPUT...\n",
            "[Numerical 15 / 28] Processing numerical column RETRANSMITTED_IN_BYTES...\n",
            "[Numerical 16 / 28] Processing numerical column NUM_PKTS_256_TO_512_BYTES...\n",
            "[Numerical 17 / 28] Processing numerical column MIN_TTL...\n",
            "[Numerical 18 / 28] Processing numerical column OUT_BYTES...\n",
            "[Numerical 19 / 28] Processing numerical column DST_TO_SRC_AVG_THROUGHPUT...\n",
            "[Numerical 20 / 28] Processing numerical column DURATION_OUT...\n",
            "[Numerical 21 / 28] Processing numerical column TCP_WIN_MAX_OUT...\n",
            "[Numerical 22 / 28] Processing numerical column MIN_IP_PKT_LEN...\n",
            "[Numerical 23 / 28] Processing numerical column MAX_IP_PKT_LEN...\n",
            "[Numerical 24 / 28] Processing numerical column DURATION_IN...\n",
            "[Numerical 25 / 28] Processing numerical column NUM_PKTS_UP_TO_128_BYTES...\n",
            "[Numerical 26 / 28] Processing numerical column RETRANSMITTED_OUT_BYTES...\n",
            "[Numerical 27 / 28] Processing numerical column NUM_PKTS_128_TO_256_BYTES...\n",
            "[Numerical 28 / 28] Processing numerical column MAX_TTL...\n",
            "Applying pre-processing to categorical values\n",
            "[Categorical 1 / 9] Processing categorical column CLIENT_TCP_FLAGS...\n",
            "Encoding the 16 levels for CLIENT_TCP_FLAGS\n",
            "[Categorical 2 / 9] Processing categorical column L4_SRC_PORT...\n",
            "Encoding the 32 levels for L4_SRC_PORT\n",
            "[Categorical 3 / 9] Processing categorical column TCP_FLAGS...\n",
            "Encoding the 17 levels for TCP_FLAGS\n",
            "[Categorical 4 / 9] Processing categorical column ICMP_IPV4_TYPE...\n",
            "Encoding the 32 levels for ICMP_IPV4_TYPE\n",
            "[Categorical 5 / 9] Processing categorical column ICMP_TYPE...\n",
            "Encoding the 32 levels for ICMP_TYPE\n",
            "[Categorical 6 / 9] Processing categorical column PROTOCOL...\n",
            "Encoding the 32 levels for PROTOCOL\n",
            "[Categorical 7 / 9] Processing categorical column SERVER_TCP_FLAGS...\n",
            "Encoding the 15 levels for SERVER_TCP_FLAGS\n",
            "[Categorical 8 / 9] Processing categorical column L4_DST_PORT...\n",
            "Encoding the 32 levels for L4_DST_PORT\n",
            "[Categorical 9 / 9] Processing categorical column L7_PROTO...\n",
            "Encoding the 32 levels for L7_PROTO\n",
            "Generating pre-processed dataframe...\n",
            "Input data frame had shape (2390275,45), output data frame has shape (2390275,270) after pre-processing...\n",
            "Writing to cache file path: demonstration/UNSW-NB15_0_QdLmZHuh8yOmlGcKBEkf7hepImY0_5EjmvToFWKee8t20u0dFpVzNu4s0.feather...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     IN_BYTES  DST_TO_SRC_SECOND_BYTES  LONGEST_FLOW_PKT  \\\n",
              "0    0.127562                 0.294070          0.565324   \n",
              "1    0.323054                 0.317800          0.565324   \n",
              "2    0.358547                 0.333895          0.575948   \n",
              "3    0.380413                 0.346818          0.598516   \n",
              "4    0.402810                 0.360391          0.598516   \n",
              "..        ...                      ...               ...   \n",
              "495  0.414039                 0.367652          0.598516   \n",
              "496  0.323054                 0.317800          0.565324   \n",
              "497  0.424305                 0.374515          0.598516   \n",
              "498  0.358547                 0.333895          0.575948   \n",
              "499  0.380413                 0.346818          0.598516   \n",
              "\n",
              "     FLOW_DURATION_MILLISECONDS  TCP_WIN_MAX_IN  SHORTEST_FLOW_PKT   IN_PKTS  \\\n",
              "0                           0.0        0.000000           0.440913  0.000000   \n",
              "1                           0.0        0.817819           0.440913  0.160324   \n",
              "2                           0.0        0.831717           0.440913  0.218877   \n",
              "3                           0.0        0.843756           0.440913  0.255508   \n",
              "4                           0.0        0.863875           0.440913  0.293311   \n",
              "..                          ...             ...                ...       ...   \n",
              "495                         0.0        0.872469           0.440913  0.312343   \n",
              "496                         0.0        0.817819           0.440913  0.160324   \n",
              "497                         0.0        0.880314           0.440913  0.328315   \n",
              "498                         0.0        0.831717           0.440913  0.218877   \n",
              "499                         0.0        0.843756           0.440913  0.255508   \n",
              "\n",
              "     NUM_PKTS_1024_TO_1514_BYTES  RETRANSMITTED_IN_PKTS  \\\n",
              "0                            0.0               0.000000   \n",
              "1                            0.0               0.074172   \n",
              "2                            0.0               0.117560   \n",
              "3                            0.0               0.148344   \n",
              "4                            0.0               0.172222   \n",
              "..                           ...                    ...   \n",
              "495                          0.0               0.191732   \n",
              "496                          0.0               0.074172   \n",
              "497                          0.0               0.208227   \n",
              "498                          0.0               0.117560   \n",
              "499                          0.0               0.148344   \n",
              "\n",
              "     SRC_TO_DST_SECOND_BYTES  ...  L7_PROTO_23  L7_PROTO_24  L7_PROTO_25  \\\n",
              "0                   0.295560  ...        False        False        False   \n",
              "1                   0.316753  ...        False        False        False   \n",
              "2                   0.329795  ...        False        False        False   \n",
              "3                   0.340052  ...        False        False        False   \n",
              "4                   0.352235  ...        False        False        False   \n",
              "..                       ...  ...          ...          ...          ...   \n",
              "495                 0.358927  ...        False        False        False   \n",
              "496                 0.316753  ...        False        False        False   \n",
              "497                 0.365353  ...        False        False        False   \n",
              "498                 0.329795  ...        False        False        False   \n",
              "499                 0.340052  ...        False        False        False   \n",
              "\n",
              "     L7_PROTO_26  L7_PROTO_27  L7_PROTO_28  L7_PROTO_29  L7_PROTO_30  \\\n",
              "0          False        False        False        False        False   \n",
              "1          False        False        False        False        False   \n",
              "2          False        False        False        False        False   \n",
              "3          False        False        False        False        False   \n",
              "4          False        False        False        False        False   \n",
              "..           ...          ...          ...          ...          ...   \n",
              "495        False        False        False        False        False   \n",
              "496        False        False        False        False        False   \n",
              "497        False        False        False        False        False   \n",
              "498        False        False        False        False        False   \n",
              "499        False        False        False        False        False   \n",
              "\n",
              "     L7_PROTO_31  L7_PROTO_32  \n",
              "0          False        False  \n",
              "1          False        False  \n",
              "2          False        False  \n",
              "3          False        False  \n",
              "4          False        False  \n",
              "..           ...          ...  \n",
              "495        False        False  \n",
              "496        False        False  \n",
              "497        False        False  \n",
              "498        False        False  \n",
              "499        False        False  \n",
              "\n",
              "[500 rows x 268 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83e2701e-4962-41b6-baf5-61798fb94cd0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IN_BYTES</th>\n",
              "      <th>DST_TO_SRC_SECOND_BYTES</th>\n",
              "      <th>LONGEST_FLOW_PKT</th>\n",
              "      <th>FLOW_DURATION_MILLISECONDS</th>\n",
              "      <th>TCP_WIN_MAX_IN</th>\n",
              "      <th>SHORTEST_FLOW_PKT</th>\n",
              "      <th>IN_PKTS</th>\n",
              "      <th>NUM_PKTS_1024_TO_1514_BYTES</th>\n",
              "      <th>RETRANSMITTED_IN_PKTS</th>\n",
              "      <th>SRC_TO_DST_SECOND_BYTES</th>\n",
              "      <th>...</th>\n",
              "      <th>L7_PROTO_23</th>\n",
              "      <th>L7_PROTO_24</th>\n",
              "      <th>L7_PROTO_25</th>\n",
              "      <th>L7_PROTO_26</th>\n",
              "      <th>L7_PROTO_27</th>\n",
              "      <th>L7_PROTO_28</th>\n",
              "      <th>L7_PROTO_29</th>\n",
              "      <th>L7_PROTO_30</th>\n",
              "      <th>L7_PROTO_31</th>\n",
              "      <th>L7_PROTO_32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.127562</td>\n",
              "      <td>0.294070</td>\n",
              "      <td>0.565324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.440913</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.295560</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.323054</td>\n",
              "      <td>0.317800</td>\n",
              "      <td>0.565324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.817819</td>\n",
              "      <td>0.440913</td>\n",
              "      <td>0.160324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.074172</td>\n",
              "      <td>0.316753</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.358547</td>\n",
              "      <td>0.333895</td>\n",
              "      <td>0.575948</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.831717</td>\n",
              "      <td>0.440913</td>\n",
              "      <td>0.218877</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.117560</td>\n",
              "      <td>0.329795</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.380413</td>\n",
              "      <td>0.346818</td>\n",
              "      <td>0.598516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.843756</td>\n",
              "      <td>0.440913</td>\n",
              "      <td>0.255508</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.148344</td>\n",
              "      <td>0.340052</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.402810</td>\n",
              "      <td>0.360391</td>\n",
              "      <td>0.598516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.863875</td>\n",
              "      <td>0.440913</td>\n",
              "      <td>0.293311</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.172222</td>\n",
              "      <td>0.352235</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>0.414039</td>\n",
              "      <td>0.367652</td>\n",
              "      <td>0.598516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.872469</td>\n",
              "      <td>0.440913</td>\n",
              "      <td>0.312343</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.191732</td>\n",
              "      <td>0.358927</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>0.323054</td>\n",
              "      <td>0.317800</td>\n",
              "      <td>0.565324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.817819</td>\n",
              "      <td>0.440913</td>\n",
              "      <td>0.160324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.074172</td>\n",
              "      <td>0.316753</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>0.424305</td>\n",
              "      <td>0.374515</td>\n",
              "      <td>0.598516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.880314</td>\n",
              "      <td>0.440913</td>\n",
              "      <td>0.328315</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.208227</td>\n",
              "      <td>0.365353</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>0.358547</td>\n",
              "      <td>0.333895</td>\n",
              "      <td>0.575948</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.831717</td>\n",
              "      <td>0.440913</td>\n",
              "      <td>0.218877</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.117560</td>\n",
              "      <td>0.329795</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>0.380413</td>\n",
              "      <td>0.346818</td>\n",
              "      <td>0.598516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.843756</td>\n",
              "      <td>0.440913</td>\n",
              "      <td>0.255508</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.148344</td>\n",
              "      <td>0.340052</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows  268 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83e2701e-4962-41b6-baf5-61798fb94cd0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-83e2701e-4962-41b6-baf5-61798fb94cd0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-83e2701e-4962-41b6-baf5-61798fb94cd0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-65540968-b0a8-40b5-b812-c276380e7fa6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-65540968-b0a8-40b5-b812-c276380e7fa6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-65540968-b0a8-40b5-b812-c276380e7fa6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the transformer model\n",
        "m = ft.build_model()\n",
        "m.summary()\n",
        "\n",
        "# Compile the model\n",
        "m.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['binary_accuracy'], jit_compile=True)"
      ],
      "metadata": {
        "id": "jrnUn2-l_ADl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d032b6bb-70ad-417d-86da-26e714cc2c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_IN_BYTES       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_DST_TO_SRC_S  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_LONGEST_FLOW  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_FLOW_DURATIO  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_TCP_WIN_MAX_  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_SHORTEST_FLO  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_IN_PKTS        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_NUM_PKTS_102  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_SRC_TO_DST_S  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_OUT_PKTS       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_NUM_PKTS_512  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_SRC_TO_DST_A  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_NUM_PKTS_256  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_MIN_TTL        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_OUT_BYTES      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_DST_TO_SRC_A  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_DURATION_OUT   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_TCP_WIN_MAX_  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_MIN_IP_PKT_L  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_MAX_IP_PKT_L  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_DURATION_IN    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_NUM_PKTS_UP_  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_NUM_PKTS_128  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_MAX_TTL        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_CLIENT_TCP_F  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_L4_SRC_PORT    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_TCP_FLAGS      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m17\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_ICMP_IPV4_TY  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_ICMP_TYPE      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_PROTOCOL       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_SERVER_TCP_F  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m15\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_L4_DST_PORT    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_L7_PROTO       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " feature_concat       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m268\u001b[0m)              \u001b[38;5;34m0\u001b[0m  input_IN_BYTES[\u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                       input_DST_TO_SRC \n",
              "                                                     input_LONGEST_FL \n",
              "                                                     input_FLOW_DURAT \n",
              "                                                     input_TCP_WIN_MA \n",
              "                                                     input_SHORTEST_F \n",
              "                                                     input_IN_PKTS[\u001b[38;5;34m0\u001b[0m] \n",
              "                                                     input_NUM_PKTS_1 \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_SRC_TO_DST \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_OUT_PKTS[\u001b[38;5;34m0\u001b[0m \n",
              "                                                     input_NUM_PKTS_5 \n",
              "                                                     input_SRC_TO_DST \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_NUM_PKTS_2 \n",
              "                                                     input_MIN_TTL[\u001b[38;5;34m0\u001b[0m] \n",
              "                                                     input_OUT_BYTES[\u001b[38;5;34m\u001b[0m \n",
              "                                                     input_DST_TO_SRC \n",
              "                                                     input_DURATION_O \n",
              "                                                     input_TCP_WIN_MA \n",
              "                                                     input_MIN_IP_PKT \n",
              "                                                     input_MAX_IP_PKT \n",
              "                                                     input_DURATION_I \n",
              "                                                     input_NUM_PKTS_U \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_NUM_PKTS_1 \n",
              "                                                     input_MAX_TTL[\u001b[38;5;34m0\u001b[0m] \n",
              "                                                     input_CLIENT_TCP \n",
              "                                                     input_L4_SRC_POR \n",
              "                                                     input_TCP_FLAGS[\u001b[38;5;34m\u001b[0m \n",
              "                                                     input_ICMP_IPV4_ \n",
              "                                                     input_ICMP_TYPE[\u001b[38;5;34m\u001b[0m \n",
              "                                                     input_PROTOCOL[\u001b[38;5;34m0\u001b[0m \n",
              "                                                     input_SERVER_TCP \n",
              "                                                     input_L4_DST_POR \n",
              "                                                     input_L7_PROTO[\u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " embed (\u001b[38;5;33mDense\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m17,216\u001b[0m  feature_concat[\u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " block_0_transforme  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m83,200\u001b[0m  embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              " (\u001b[38;5;33mTransformerEncode\u001b[0m                                                   \n",
              "\n",
              " block_1_transforme  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m83,200\u001b[0m  block_0_transfor \n",
              " (\u001b[38;5;33mTransformerEncode\u001b[0m                                                   \n",
              "\n",
              " slice_last (\u001b[38;5;33mLambda\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  block_1_transfor \n",
              "\n",
              " classification_mlp  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)             \u001b[38;5;34m8,320\u001b[0m  slice_last[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              " (\u001b[38;5;33mDense\u001b[0m)                                                               \n",
              "\n",
              " dropout_2 (\u001b[38;5;33mDropout\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  classification_m \n",
              "\n",
              " binary_classificat  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 \u001b[38;5;34m129\u001b[0m  dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              " (\u001b[38;5;33mDense\u001b[0m)                                                               \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " input_IN_BYTES       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_DST_TO_SRC_S  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_LONGEST_FLOW  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_FLOW_DURATIO  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_TCP_WIN_MAX_  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_SHORTEST_FLO  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_IN_PKTS        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_NUM_PKTS_102  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_SRC_TO_DST_S  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_OUT_PKTS       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_NUM_PKTS_512  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_SRC_TO_DST_A  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_NUM_PKTS_256  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_MIN_TTL        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_OUT_BYTES      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_DST_TO_SRC_A  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_DURATION_OUT   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_TCP_WIN_MAX_  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_MIN_IP_PKT_L  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_MAX_IP_PKT_L  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_DURATION_IN    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_NUM_PKTS_UP_  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_NUM_PKTS_128  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_MAX_TTL        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_CLIENT_TCP_F  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_L4_SRC_PORT    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_TCP_FLAGS      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_ICMP_IPV4_TY  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_ICMP_TYPE      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_PROTOCOL       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_SERVER_TCP_F  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_L4_DST_PORT    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_L7_PROTO       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " feature_concat       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">268</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  input_IN_BYTES[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       input_DST_TO_SRC \n",
              "                                                     input_LONGEST_FL \n",
              "                                                     input_FLOW_DURAT \n",
              "                                                     input_TCP_WIN_MA \n",
              "                                                     input_SHORTEST_F \n",
              "                                                     input_IN_PKTS[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "                                                     input_NUM_PKTS_1 \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_SRC_TO_DST \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_OUT_PKTS[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                                                     input_NUM_PKTS_5 \n",
              "                                                     input_SRC_TO_DST \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_NUM_PKTS_2 \n",
              "                                                     input_MIN_TTL[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "                                                     input_OUT_BYTES[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                                                     input_DST_TO_SRC \n",
              "                                                     input_DURATION_O \n",
              "                                                     input_TCP_WIN_MA \n",
              "                                                     input_MIN_IP_PKT \n",
              "                                                     input_MAX_IP_PKT \n",
              "                                                     input_DURATION_I \n",
              "                                                     input_NUM_PKTS_U \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_NUM_PKTS_1 \n",
              "                                                     input_MAX_TTL[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "                                                     input_CLIENT_TCP \n",
              "                                                     input_L4_SRC_POR \n",
              "                                                     input_TCP_FLAGS[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                                                     input_ICMP_IPV4_ \n",
              "                                                     input_ICMP_TYPE[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                                                     input_PROTOCOL[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                                                     input_SERVER_TCP \n",
              "                                                     input_L4_DST_POR \n",
              "                                                     input_L7_PROTO[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " embed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span>  feature_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " block_0_transforme  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">83,200</span>  embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode</span>                                                   \n",
              "\n",
              " block_1_transforme  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">83,200</span>  block_0_transfor \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode</span>                                                   \n",
              "\n",
              " slice_last (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  block_1_transfor \n",
              "\n",
              " classification_mlp  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span>  slice_last[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                               \n",
              "\n",
              " dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  classification_m \n",
              "\n",
              " binary_classificat  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>  dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                               \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m192,065\u001b[0m (750.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192,065</span> (750.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m192,065\u001b[0m (750.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192,065</span> (750.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_results, eval_results, final_epoch) = ft.evaluate(m, batch_size=128, epochs=5, steps_per_epoch=64, early_stopping_patience=5)"
      ],
      "metadata": {
        "id": "n_R5uFnWG24q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97af0b95-b94b-4500-8903-97694a7629bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building eval dataset...\n",
            "Splitting dataset to featurewise...\n",
            "Evaluation dataset is built!\n",
            "Positive samples in eval set: 16271\n",
            "Negative samples in eval set: 222756\n",
            "Epoch = 0 / 5 (early stop in 5), step = 0, loss = 0.72748, results = [array(0.72747767, dtype=float32), array(0.484375, dtype=float32)] -- elapsed (train): 0.00s\n",
            "Epoch = 0 / 5 (early stop in 5), step = 14, loss = 0.44843, results = [array(0.44842574, dtype=float32), array(0.78333336, dtype=float32)] -- elapsed (train): 1.13s\n",
            "Epoch = 0 / 5 (early stop in 5), step = 28, loss = 0.30065, results = [array(0.30065006, dtype=float32), array(0.86880386, dtype=float32)] -- elapsed (train): 2.24s\n",
            "Epoch = 0 / 5 (early stop in 5), step = 36, loss = 0.25780, results = [array(0.25780153, dtype=float32), array(0.8904139, dtype=float32)] -- elapsed (train): 3.27s\n",
            "Epoch = 0 / 5 (early stop in 5), step = 48, loss = 0.20583, results = [array(0.20582652, dtype=float32), array(0.91470027, dtype=float32)] -- elapsed (train): 4.34s\n",
            "Epoch = 0 / 5 (early stop in 5), step = 62, loss = 0.16851, results = [array(0.16850877, dtype=float32), array(0.9309276, dtype=float32)] -- elapsed (train): 5.41s\n",
            "Epoch = 1 / 5 (early stop in 5), step = 10, loss = 0.14704, results = [array(0.14704405, dtype=float32), array(0.94083333, dtype=float32)] -- elapsed (train): 6.35s\n",
            "Epoch = 1 / 5 (early stop in 5), step = 23, loss = 0.13122, results = [array(0.13121979, dtype=float32), array(0.9482422, dtype=float32)] -- elapsed (train): 7.53s\n",
            "Epoch = 1 / 5 (early stop in 5), step = 31, loss = 0.12255, results = [array(0.12255359, dtype=float32), array(0.9520671, dtype=float32)] -- elapsed (train): 8.55s\n",
            "Epoch = 1 / 5 (early stop in 5), step = 45, loss = 0.11171, results = [array(0.11170708, dtype=float32), array(0.9571733, dtype=float32)] -- elapsed (train): 9.64s\n",
            "Epoch = 1 / 5 (early stop in 5), step = 59, loss = 0.10418, results = [array(0.10417648, dtype=float32), array(0.9607485, dtype=float32)] -- elapsed (train): 10.71s\n",
            "Epoch = 2 / 5 (early stop in 5), step = 9, loss = 0.09746, results = [array(0.09745628, dtype=float32), array(0.96399456, dtype=float32)] -- elapsed (train): 11.75s\n",
            "Epoch = 2 / 5 (early stop in 5), step = 19, loss = 0.09277, results = [array(0.09277145, dtype=float32), array(0.9660051, dtype=float32)] -- elapsed (train): 12.82s\n",
            "Epoch = 2 / 5 (early stop in 5), step = 29, loss = 0.08895, results = [array(0.0889492, dtype=float32), array(0.9678105, dtype=float32)] -- elapsed (train): 13.86s\n",
            "Epoch = 2 / 5 (early stop in 5), step = 44, loss = 0.08462, results = [array(0.084625, dtype=float32), array(0.97005963, dtype=float32)] -- elapsed (train): 15.02s\n",
            "Epoch = 2 / 5 (early stop in 5), step = 58, loss = 0.07992, results = [array(0.07992409, dtype=float32), array(0.9718416, dtype=float32)] -- elapsed (train): 16.13s\n",
            "Epoch = 3 / 5 (early stop in 5), step = 8, loss = 0.07578, results = [array(0.07577745, dtype=float32), array(0.9733753, dtype=float32)] -- elapsed (train): 17.28s\n",
            "Epoch = 3 / 5 (early stop in 5), step = 16, loss = 0.07452, results = [array(0.07452256, dtype=float32), array(0.9740954, dtype=float32)] -- elapsed (train): 18.31s\n",
            "Epoch = 3 / 5 (early stop in 5), step = 28, loss = 0.07164, results = [array(0.07164385, dtype=float32), array(0.9752899, dtype=float32)] -- elapsed (train): 19.33s\n",
            "Epoch = 3 / 5 (early stop in 5), step = 43, loss = 0.06889, results = [array(0.06889465, dtype=float32), array(0.9764632, dtype=float32)] -- elapsed (train): 20.49s\n",
            "Epoch = 3 / 5 (early stop in 5), step = 58, loss = 0.06633, results = [array(0.0663267, dtype=float32), array(0.9775274, dtype=float32)] -- elapsed (train): 21.63s\n",
            "Epoch = 4 / 5 (early stop in 5), step = 5, loss = 0.06436, results = [array(0.0643619, dtype=float32), array(0.9783218, dtype=float32)] -- elapsed (train): 22.67s\n",
            "Epoch = 4 / 5 (early stop in 5), step = 14, loss = 0.06292, results = [array(0.06292433, dtype=float32), array(0.9788688, dtype=float32)] -- elapsed (train): 23.71s\n",
            "Epoch = 4 / 5 (early stop in 5), step = 28, loss = 0.06144, results = [array(0.06144443, dtype=float32), array(0.9796327, dtype=float32)] -- elapsed (train): 24.79s\n",
            "Epoch = 4 / 5 (early stop in 5), step = 43, loss = 0.06030, results = [array(0.06030356, dtype=float32), array(0.98026043, dtype=float32)] -- elapsed (train): 25.93s\n",
            "Epoch = 4 / 5 (early stop in 5), step = 58, loss = 0.05849, results = [array(0.05848818, dtype=float32), array(0.9809276, dtype=float32)] -- elapsed (train): 27.10s\n",
            "\u001b[1m7470/7470\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 12ms/step\n",
            "Epoch 4 yielded predictions: (239027,), overall balanced accuracy: 99.19%, TP = 16,200 / 16,271, TN = 220,137 / 222,756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementation**\n",
        "\n",
        "Multi Class Classification\n",
        "ref: https://github.com/liamdm/FlowTransformer/blob/master/framework/flow_transformer.py#L300\n",
        "\n",
        "SIAN\n"
      ],
      "metadata": {
        "id": "FJ83nGDe472Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from framework.base_classification_head import BaseClassificationHead\n",
        "from framework.base_input_encoding import BaseInputEncoding\n",
        "from framework.base_preprocessing import BasePreProcessing\n",
        "from framework.dataset_specification import DatasetSpecification\n",
        "from framework.enumerations import EvaluationDatasetSampling, CategoricalFormat\n",
        "from framework.flow_transformer_parameters import FlowTransformerParameters\n",
        "from framework.framework_component import FunctionalComponent\n",
        "from framework.model_input_specification import ModelInputSpecification\n",
        "from framework.utilities import get_identifier, load_feather_plus_metadata, save_feather_plus_metadata\n",
        "\n",
        "from keras import Input, Model\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "import time\n",
        "from typing import override\n",
        "\n",
        "# SIAN\n",
        "class FlowTransformerMultiClass(FlowTransformer):\n",
        "    def __init__(self, pre_processing:BasePreProcessing,\n",
        "                 input_encoding:BaseInputEncoding,\n",
        "                 sequential_model:FunctionalComponent,\n",
        "                 classification_head:BaseClassificationHead,\n",
        "                 params:FlowTransformerParameters,\n",
        "                 rs:np.random.RandomState=None):\n",
        "        super().__init__(pre_processing, input_encoding, sequential_model, classification_head, params, rs)\n",
        "\n",
        "    # SIAN\n",
        "    def multiclass_encoding(self, labels:List):\n",
        "        if self.y is None:\n",
        "            raise Exception(\"Please call load_dataset before calling multiclass_encoding\")\n",
        "\n",
        "        self.output_size = len(labels)\n",
        "        self.label_encode = {label:index for index, label in enumerate(labels)}\n",
        "        self.label_decode = {index:label for index, label in enumerate(labels)}\n",
        "        self.y = np.array([self.label_encode[label] for label in self.y])\n",
        "\n",
        "    @override\n",
        "    def build_model(self, prefix:str=None):\n",
        "        if prefix is None:\n",
        "            prefix = \"\"\n",
        "\n",
        "        if self.X is None:\n",
        "            raise Exception(\"Please call load_dataset before calling build_model()\")\n",
        "\n",
        "        m_inputs = []\n",
        "        for numeric_feature in self.model_input_spec.numeric_feature_names:\n",
        "            m_input = Input((self.parameters.window_size, 1), name=f\"{prefix}input_{numeric_feature}\", dtype=\"float32\")\n",
        "            m_inputs.append(m_input)\n",
        "\n",
        "        for categorical_feature_name, categorical_feature_levels in \\\n",
        "            zip(self.model_input_spec.categorical_feature_names, self.model_input_spec.levels_per_categorical_feature):\n",
        "            m_input = Input(\n",
        "                (self.parameters.window_size, 1 if self.model_input_spec.categorical_format == CategoricalFormat.Integers else categorical_feature_levels),\n",
        "                name=f\"{prefix}input_{categorical_feature_name}\",\n",
        "                dtype=\"int32\" if self.model_input_spec.categorical_format == CategoricalFormat.Integers else \"float32\"\n",
        "            )\n",
        "            m_inputs.append(m_input)\n",
        "\n",
        "        self.input_encoding.build(self.parameters.window_size, self.model_input_spec)\n",
        "        self.sequential_model.build(self.parameters.window_size, self.model_input_spec)\n",
        "        self.classification_head.build(self.parameters.window_size, self.model_input_spec)\n",
        "\n",
        "        m_x = self.input_encoding.apply(m_inputs, prefix)\n",
        "\n",
        "        # in case the classification head needs to add tokens at this stage\n",
        "        m_x = self.classification_head.apply_before_transformer(m_x, prefix)\n",
        "\n",
        "        m_x = self.sequential_model.apply(m_x, prefix)\n",
        "        m_x = self.classification_head.apply(m_x, prefix)\n",
        "\n",
        "        for layer_i, layer_size in enumerate(self.parameters.mlp_layer_sizes):\n",
        "            m_x = Dense(layer_size, activation=\"relu\", name=f\"{prefix}classification_mlp_{layer_i}_{layer_size}\")(m_x)\n",
        "            m_x = Dropout(self.parameters.mlp_dropout)(m_x) if self.parameters.mlp_dropout > 0 else m_x\n",
        "\n",
        "        # SIAN\n",
        "        m_x = Dense(self.output_size, activation=\"softmax\", name=f\"{prefix}multiclass_classification_out\")(m_x)\n",
        "        m = Model(m_inputs, m_x)\n",
        "        #m.summary()\n",
        "        return m\n",
        "\n",
        "    @override\n",
        "    def evaluate(self, m:keras.Model, batch_size, early_stopping_patience:int, epochs:int=100, steps_per_epoch:int=128):\n",
        "        n_malicious_per_batch = int(0.5 * batch_size)\n",
        "        n_legit_per_batch = batch_size - n_malicious_per_batch\n",
        "\n",
        "        overall_y_preserve = np.zeros(dtype=\"float32\", shape=(n_malicious_per_batch + n_legit_per_batch,))\n",
        "        overall_y_preserve[:n_malicious_per_batch] = 1.\n",
        "\n",
        "        selectable_mask = np.zeros(len(self.X), dtype=bool)\n",
        "        selectable_mask[self.parameters.window_size:-self.parameters.window_size] = True\n",
        "        train_mask = self.training_mask\n",
        "\n",
        "        y_mask = ~(self.y == self.label_encode[str(self.dataset_specification.benign_label)])\n",
        "\n",
        "        indices_train = np.argwhere(train_mask).reshape(-1)\n",
        "        malicious_indices_train = np.argwhere(train_mask & y_mask & selectable_mask).reshape(-1)\n",
        "        legit_indices_train = np.argwhere(train_mask & ~y_mask & selectable_mask).reshape(-1)\n",
        "\n",
        "        indices_test:np.ndarray = np.argwhere(~train_mask).reshape(-1)\n",
        "\n",
        "        def get_windows_for_indices(indices:np.ndarray, ordered) -> List[pd.DataFrame]:\n",
        "            X: List[pd.DataFrame] = []\n",
        "\n",
        "            if ordered:\n",
        "                # we don't really want to include eval samples as part of context, because out of range values might be learned\n",
        "                # by the model, _but_ we are forced to in the windowed approach, if users haven't just selected the\n",
        "                # \"take last 10%\" as eval option. We warn them prior to this though.\n",
        "                for i1 in indices:\n",
        "                    X.append(self.X.iloc[(i1 - self.parameters.window_size) + 1:i1 + 1])\n",
        "            else:\n",
        "                context_indices_batch = np.random.choice(indices_train, size=(batch_size, self.parameters.window_size),\n",
        "                                                         replace=False).reshape(-1)\n",
        "                context_indices_batch[:, -1] = indices\n",
        "\n",
        "                for index in context_indices_batch:\n",
        "                    X.append(self.X.iloc[index])\n",
        "\n",
        "            return X\n",
        "\n",
        "        feature_columns_map = {}\n",
        "\n",
        "        def samplewise_to_featurewise(X):\n",
        "            sequence_length = len(X[0])\n",
        "\n",
        "            combined_df = pd.concat(X)\n",
        "\n",
        "            featurewise_X = []\n",
        "\n",
        "            if len(feature_columns_map) == 0:\n",
        "                for feature in self.model_input_spec.feature_names:\n",
        "                    if feature in self.model_input_spec.numeric_feature_names or self.model_input_spec.categorical_format == CategoricalFormat.Integers:\n",
        "                        feature_columns_map[feature] = feature\n",
        "                    else:\n",
        "                        # this is a one-hot encoded categorical feature\n",
        "                        feature_columns_map[feature] = [c for c in X[0].columns if str(c).startswith(feature)]\n",
        "\n",
        "            for feature in self.model_input_spec.feature_names:\n",
        "                feature_columns = feature_columns_map[feature]\n",
        "                combined_values = combined_df[feature_columns].values\n",
        "\n",
        "                # maybe this can be faster with a reshape but I couldn't get it to work\n",
        "                combined_values = np.array([combined_values[i:i+sequence_length] for i in range(0, len(combined_values), sequence_length)])\n",
        "                featurewise_X.append(combined_values)\n",
        "\n",
        "            return featurewise_X\n",
        "\n",
        "        print(f\"Building eval dataset...\")\n",
        "        eval_X = get_windows_for_indices(indices_test, True)\n",
        "        print(f\"Splitting dataset to featurewise...\")\n",
        "        eval_featurewise_X = samplewise_to_featurewise(eval_X)\n",
        "\n",
        "        print(f\"Evaluation dataset is built!\")\n",
        "\n",
        "        # SIAN\n",
        "        eval_y = self.y[indices_test]\n",
        "\n",
        "        print(\"Evaluation dataset size: %d\" %np.count_nonzero(indices_test))\n",
        "        for key, value in self.label_encode.items():\n",
        "            print(\"Label: %s(%d)\" %(key, value))\n",
        "            eval_P = (eval_y == value)\n",
        "            n_eval_P = np.count_nonzero(eval_P)\n",
        "            eval_N = ~eval_P\n",
        "            n_eval_N = np.count_nonzero(eval_N)\n",
        "            print(f\"Positive samples in eval set: {n_eval_P}\")\n",
        "            print(f\"Negative samples in eval set: {n_eval_N}\")\n",
        "\n",
        "        epoch_results = []\n",
        "\n",
        "        def run_evaluation(epoch):\n",
        "            # SIAN\n",
        "            pred_y = m.predict(eval_featurewise_X, verbose=True)\n",
        "            pred_y = pred_y.argmax(axis=1).reshape(-1)\n",
        "\n",
        "            print(f\"Epoch {epoch} yielded predictions: {pred_y.shape}\")\n",
        "            for key, value in self.label_encode.items():\n",
        "                pred_P = (pred_y == value)\n",
        "                n_pred_P = np.count_nonzero(pred_P)\n",
        "                pred_N = ~pred_P\n",
        "                n_pred_N = np.count_nonzero(pred_N)\n",
        "\n",
        "                eval_P = (eval_y == value)\n",
        "                n_eval_P = np.count_nonzero(eval_P)\n",
        "                eval_N = ~eval_P\n",
        "                n_eval_N = np.count_nonzero(eval_N)\n",
        "\n",
        "                TP = np.count_nonzero(pred_P & eval_P)\n",
        "                FP = np.count_nonzero(pred_P & eval_N)\n",
        "                TN = np.count_nonzero(pred_N & eval_N)\n",
        "                FN = np.count_nonzero(pred_N & eval_P)\n",
        "\n",
        "                sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "                specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "                balanced_accuracy = (sensitivity + specificity) / 2\n",
        "\n",
        "                precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "                recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "\n",
        "                f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "                print(f\"[{key} -- overall balanced accuracy: {balanced_accuracy * 100:.2f}%, TP = {TP:,} / {n_eval_P:,}, TN = {TN:,} / {n_eval_N:,}\")\n",
        "\n",
        "                epoch_results.append({\n",
        "                    \"epoch\": epoch,\n",
        "                    \"label\": key,\n",
        "                    \"P\": n_eval_P,\n",
        "                    \"N\": n_eval_N,\n",
        "                    \"pred_P\": n_pred_P,\n",
        "                    \"pred_N\": n_pred_N,\n",
        "                    \"TP\": TP,\n",
        "                    \"FP\": FP,\n",
        "                    \"TN\": TN,\n",
        "                    \"FN\": FN,\n",
        "                    \"bal_acc\": balanced_accuracy,\n",
        "                    \"f1\": f1_score\n",
        "                })\n",
        "\n",
        "        # SIAN\n",
        "        y = self.y\n",
        "\n",
        "        class BatchYielder():\n",
        "            def __init__(self, ordered, random, rs):\n",
        "                self.ordered = ordered\n",
        "                self.random = random\n",
        "                self.cursor_malicious = 0\n",
        "                self.cursor_legit = 0\n",
        "                self.rs = rs\n",
        "\n",
        "            def get_batch(self):\n",
        "                malicious_indices_batch = self.rs.choice(malicious_indices_train, size=n_malicious_per_batch,\n",
        "                                                         replace=False) \\\n",
        "                    if self.random else \\\n",
        "                    malicious_indices_train[self.cursor_malicious:self.cursor_malicious + n_malicious_per_batch]\n",
        "\n",
        "                legitimate_indices_batch = self.rs.choice(legit_indices_train, size=n_legit_per_batch, replace=False) \\\n",
        "                    if self.random else \\\n",
        "                    legit_indices_train[self.cursor_legit:self.cursor_legit + n_legit_per_batch]\n",
        "\n",
        "                indices = np.concatenate([malicious_indices_batch, legitimate_indices_batch])\n",
        "\n",
        "                self.cursor_malicious = self.cursor_malicious + n_malicious_per_batch\n",
        "                self.cursor_malicious = self.cursor_malicious % (len(malicious_indices_train) - n_malicious_per_batch)\n",
        "\n",
        "                self.cursor_legit = self.cursor_legit + n_legit_per_batch\n",
        "                self.cursor_legit = self.cursor_legit % (len(legit_indices_train) - n_legit_per_batch)\n",
        "\n",
        "                X = get_windows_for_indices(indices, self.ordered)\n",
        "                # each x in X contains a dataframe, with window_size rows and all the features of the flows. There are batch_size of these.\n",
        "\n",
        "                # we have a dataframe containing batch_size x (window_size, features)\n",
        "                # we actually want a result of features x (batch_size, sequence_length, feature_dimension)\n",
        "                featurewise_X = samplewise_to_featurewise(X)\n",
        "                # SIAN\n",
        "                batch_y = y[indices]\n",
        "                # return featurewise_X, overall_y_preserve\n",
        "                return featurewise_X, batch_y\n",
        "\n",
        "        batch_yielder = BatchYielder(self.parameters._train_ensure_flows_are_ordered_within_windows, not self.parameters._train_draw_sequential_windows, self.rs)\n",
        "\n",
        "        min_loss = 100\n",
        "        iters_since_loss_decrease = 0\n",
        "\n",
        "        train_results = []\n",
        "        final_epoch = 0\n",
        "\n",
        "        last_print = time.time()\n",
        "        elapsed_time = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            final_epoch = epoch\n",
        "\n",
        "            has_reduced_loss = False\n",
        "            for step in range(steps_per_epoch):\n",
        "                batch_X, batch_y = batch_yielder.get_batch()\n",
        "\n",
        "                t0 = time.time()\n",
        "                batch_results = m.train_on_batch(batch_X, batch_y)\n",
        "                t1 = time.time()\n",
        "\n",
        "                if epoch > 0 or step > 0:\n",
        "                    elapsed_time += (t1 - t0)\n",
        "                    if epoch == 0 and step == 1:\n",
        "                        # include time for last \"step\" that we skipped with step > 0 for epoch == 0\n",
        "                        elapsed_time *= 2\n",
        "\n",
        "                train_results.append(batch_results + [elapsed_time, epoch])\n",
        "\n",
        "                batch_loss = batch_results[0] if isinstance(batch_results, list) else batch_results\n",
        "\n",
        "                if time.time() - last_print > 3:\n",
        "                    last_print = time.time()\n",
        "                    early_stop_phrase = \"\" if early_stopping_patience <= 0 else f\" (early stop in {early_stopping_patience - iters_since_loss_decrease:,})\"\n",
        "                    print(f\"Epoch = {epoch:,} / {epochs:,}{early_stop_phrase}, step = {step}, loss = {batch_loss:.5f}, results = {batch_results} -- elapsed (train): {elapsed_time:.2f}s\")\n",
        "\n",
        "                if batch_loss < min_loss:\n",
        "                    has_reduced_loss = True\n",
        "                    min_loss = batch_loss\n",
        "\n",
        "            if has_reduced_loss:\n",
        "                iters_since_loss_decrease = 0\n",
        "            else:\n",
        "                iters_since_loss_decrease += 1\n",
        "\n",
        "            do_early_stop = early_stopping_patience > 0 and iters_since_loss_decrease > early_stopping_patience\n",
        "            is_last_epoch = epoch == epochs - 1\n",
        "            run_eval = epoch in [6] or is_last_epoch or do_early_stop\n",
        "\n",
        "            if run_eval:\n",
        "                run_evaluation(epoch)\n",
        "\n",
        "            if do_early_stop:\n",
        "                print(f\"Early stopping at epoch: {epoch}\")\n",
        "                break\n",
        "\n",
        "        eval_results = pd.DataFrame(epoch_results)\n",
        "\n",
        "        return (train_results, eval_results, final_epoch)\n"
      ],
      "metadata": {
        "id": "TPqV-fKFH4_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "implementation_folder = \"implementation\"\n",
        "\n",
        "if not os.path.exists(implementation_folder):\n",
        "    os.mkdir(implementation_folder)\n",
        "\n",
        "from framework.dataset_specification import DatasetSpecification\n",
        "flow_format = DatasetSpecification(\n",
        "        include_fields=['NUM_PKTS_UP_TO_128_BYTES', 'SRC_TO_DST_SECOND_BYTES', 'OUT_PKTS', 'OUT_BYTES', 'NUM_PKTS_128_TO_256_BYTES', 'DST_TO_SRC_AVG_THROUGHPUT', 'DURATION_IN', 'L4_SRC_PORT', 'ICMP_TYPE', 'PROTOCOL', 'SERVER_TCP_FLAGS', 'IN_PKTS', 'NUM_PKTS_512_TO_1024_BYTES', 'CLIENT_TCP_FLAGS', 'TCP_WIN_MAX_IN', 'NUM_PKTS_256_TO_512_BYTES', 'SHORTEST_FLOW_PKT', 'MIN_IP_PKT_LEN', 'LONGEST_FLOW_PKT', 'L4_DST_PORT', 'MIN_TTL', 'DST_TO_SRC_SECOND_BYTES', 'NUM_PKTS_1024_TO_1514_BYTES', 'DURATION_OUT', 'FLOW_DURATION_MILLISECONDS', 'TCP_FLAGS', 'MAX_TTL', 'SRC_TO_DST_AVG_THROUGHPUT', 'ICMP_IPV4_TYPE', 'MAX_IP_PKT_LEN', 'RETRANSMITTED_OUT_BYTES', 'IN_BYTES', 'RETRANSMITTED_IN_BYTES', 'TCP_WIN_MAX_OUT', 'L7_PROTO', 'RETRANSMITTED_OUT_PKTS', 'RETRANSMITTED_IN_PKTS'],\n",
        "        categorical_fields=['CLIENT_TCP_FLAGS', 'L4_SRC_PORT', 'TCP_FLAGS', 'ICMP_IPV4_TYPE', 'ICMP_TYPE', 'PROTOCOL', 'SERVER_TCP_FLAGS', 'L4_DST_PORT', 'L7_PROTO'],\n",
        "        class_column=\"Attack\",\n",
        "        benign_label=\"Benign\"\n",
        "    )\n",
        "\n",
        "from framework.flow_transformer_parameters import FlowTransformerParameters\n",
        "from framework.flow_transformer import FlowTransformer\n",
        "\n",
        "pre_processing = StandardPreProcessing(n_categorical_levels=32)\n",
        "encoding = RecordLevelEmbed(64)\n",
        "transformer = BasicTransformer(n_layers=2, internal_size=128, n_heads=2)\n",
        "classification_head = LastTokenClassificationHead()\n",
        "\n",
        "# Define the transformer\n",
        "# SIAN\n",
        "ft = FlowTransformerMultiClass(pre_processing=pre_processing,\n",
        "                     input_encoding=encoding,\n",
        "                     sequential_model=transformer,\n",
        "                     classification_head=classification_head,\n",
        "                     params=FlowTransformerParameters(window_size=8, mlp_layer_sizes=[128], mlp_dropout=0.1))\n",
        "\n",
        "from framework.enumerations import EvaluationDatasetSampling\n",
        "from IPython.display import display\n",
        "\n",
        "# SIAN\n",
        "df = ft.load_dataset(\"UNSW-NB15\",\n",
        "                    data_path+datasets[1],\n",
        "                    specification=flow_format,\n",
        "                    evaluation_dataset_sampling=EvaluationDatasetSampling.LastRows,\n",
        "                    evaluation_percent=0.1,\n",
        "                    cache_path=implementation_folder)\n",
        "\n",
        "# SIAN\n",
        "labels = np.unique(ft.y)\n",
        "ft.multiclass_encoding(labels)\n",
        "\n",
        "# Build the transformer model\n",
        "m = ft.build_model()\n",
        "m.summary()\n",
        "\n",
        "# Compile the model\n",
        "m.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'], jit_compile=True)\n",
        "\n",
        "(train_results, eval_results, final_epoch) = ft.evaluate(m, batch_size=128, epochs=5, steps_per_epoch=64, early_stopping_patience=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-9GHKgL4_7As",
        "outputId": "e66e3bb1-47f2-4096-9e40-756555fc5ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cache file path: implementation/UNSW-NB15_0_QdLmZHuh8yOmlGcKBEkf7hepImY0_5EjmvToFWKee8t20u0dFpVzNu4s0.feather\n",
            "Reading directly from cache implementation/UNSW-NB15_0_QdLmZHuh8yOmlGcKBEkf7hepImY0_5EjmvToFWKee8t20u0dFpVzNu4s0.feather...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_IN_BYTES       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_DST_TO_SRC_S  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_LONGEST_FLOW  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_FLOW_DURATIO  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_TCP_WIN_MAX_  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_SHORTEST_FLO  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_IN_PKTS        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_NUM_PKTS_102  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_SRC_TO_DST_S  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_OUT_PKTS       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_NUM_PKTS_512  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_SRC_TO_DST_A  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_NUM_PKTS_256  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_MIN_TTL        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_OUT_BYTES      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_DST_TO_SRC_A  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_DURATION_OUT   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_TCP_WIN_MAX_  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_MIN_IP_PKT_L  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_MAX_IP_PKT_L  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_DURATION_IN    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_NUM_PKTS_UP_  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_NUM_PKTS_128  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_MAX_TTL        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_CLIENT_TCP_F  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_L4_SRC_PORT    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_TCP_FLAGS      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m17\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_ICMP_IPV4_TY  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_ICMP_TYPE      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_PROTOCOL       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_SERVER_TCP_F  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m15\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_L4_DST_PORT    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_L7_PROTO       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " feature_concat       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m268\u001b[0m)              \u001b[38;5;34m0\u001b[0m  input_IN_BYTES[\u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                       input_DST_TO_SRC \n",
              "                                                     input_LONGEST_FL \n",
              "                                                     input_FLOW_DURAT \n",
              "                                                     input_TCP_WIN_MA \n",
              "                                                     input_SHORTEST_F \n",
              "                                                     input_IN_PKTS[\u001b[38;5;34m0\u001b[0m] \n",
              "                                                     input_NUM_PKTS_1 \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_SRC_TO_DST \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_OUT_PKTS[\u001b[38;5;34m0\u001b[0m \n",
              "                                                     input_NUM_PKTS_5 \n",
              "                                                     input_SRC_TO_DST \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_NUM_PKTS_2 \n",
              "                                                     input_MIN_TTL[\u001b[38;5;34m0\u001b[0m] \n",
              "                                                     input_OUT_BYTES[\u001b[38;5;34m\u001b[0m \n",
              "                                                     input_DST_TO_SRC \n",
              "                                                     input_DURATION_O \n",
              "                                                     input_TCP_WIN_MA \n",
              "                                                     input_MIN_IP_PKT \n",
              "                                                     input_MAX_IP_PKT \n",
              "                                                     input_DURATION_I \n",
              "                                                     input_NUM_PKTS_U \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_NUM_PKTS_1 \n",
              "                                                     input_MAX_TTL[\u001b[38;5;34m0\u001b[0m] \n",
              "                                                     input_CLIENT_TCP \n",
              "                                                     input_L4_SRC_POR \n",
              "                                                     input_TCP_FLAGS[\u001b[38;5;34m\u001b[0m \n",
              "                                                     input_ICMP_IPV4_ \n",
              "                                                     input_ICMP_TYPE[\u001b[38;5;34m\u001b[0m \n",
              "                                                     input_PROTOCOL[\u001b[38;5;34m0\u001b[0m \n",
              "                                                     input_SERVER_TCP \n",
              "                                                     input_L4_DST_POR \n",
              "                                                     input_L7_PROTO[\u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " embed (\u001b[38;5;33mDense\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m17,216\u001b[0m  feature_concat[\u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " block_0_transforme  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m83,200\u001b[0m  embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              " (\u001b[38;5;33mTransformerEncode\u001b[0m                                                   \n",
              "\n",
              " block_1_transforme  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m83,200\u001b[0m  block_0_transfor \n",
              " (\u001b[38;5;33mTransformerEncode\u001b[0m                                                   \n",
              "\n",
              " slice_last (\u001b[38;5;33mLambda\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  block_1_transfor \n",
              "\n",
              " classification_mlp  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)             \u001b[38;5;34m8,320\u001b[0m  slice_last[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              " (\u001b[38;5;33mDense\u001b[0m)                                                               \n",
              "\n",
              " dropout_23           (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  classification_m \n",
              " (\u001b[38;5;33mDropout\u001b[0m)                                                             \n",
              "\n",
              " multiclass_classif  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)              \u001b[38;5;34m1,290\u001b[0m  dropout_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              " (\u001b[38;5;33mDense\u001b[0m)                                                               \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " input_IN_BYTES       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_DST_TO_SRC_S  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_LONGEST_FLOW  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_FLOW_DURATIO  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_TCP_WIN_MAX_  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_SHORTEST_FLO  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_IN_PKTS        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_NUM_PKTS_102  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_SRC_TO_DST_S  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_OUT_PKTS       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_NUM_PKTS_512  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_SRC_TO_DST_A  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_NUM_PKTS_256  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_MIN_TTL        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_OUT_BYTES      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_DST_TO_SRC_A  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_DURATION_OUT   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_TCP_WIN_MAX_  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_MIN_IP_PKT_L  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_MAX_IP_PKT_L  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_DURATION_IN    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_NUM_PKTS_UP_  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_NUM_PKTS_128  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_MAX_TTL        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_CLIENT_TCP_F  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_L4_SRC_PORT    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_TCP_FLAGS      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_ICMP_IPV4_TY  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_ICMP_TYPE      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_PROTOCOL       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_SERVER_TCP_F  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_L4_DST_PORT    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_L7_PROTO       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " feature_concat       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">268</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  input_IN_BYTES[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       input_DST_TO_SRC \n",
              "                                                     input_LONGEST_FL \n",
              "                                                     input_FLOW_DURAT \n",
              "                                                     input_TCP_WIN_MA \n",
              "                                                     input_SHORTEST_F \n",
              "                                                     input_IN_PKTS[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "                                                     input_NUM_PKTS_1 \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_SRC_TO_DST \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_OUT_PKTS[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                                                     input_NUM_PKTS_5 \n",
              "                                                     input_SRC_TO_DST \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_NUM_PKTS_2 \n",
              "                                                     input_MIN_TTL[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "                                                     input_OUT_BYTES[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                                                     input_DST_TO_SRC \n",
              "                                                     input_DURATION_O \n",
              "                                                     input_TCP_WIN_MA \n",
              "                                                     input_MIN_IP_PKT \n",
              "                                                     input_MAX_IP_PKT \n",
              "                                                     input_DURATION_I \n",
              "                                                     input_NUM_PKTS_U \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_NUM_PKTS_1 \n",
              "                                                     input_MAX_TTL[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "                                                     input_CLIENT_TCP \n",
              "                                                     input_L4_SRC_POR \n",
              "                                                     input_TCP_FLAGS[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                                                     input_ICMP_IPV4_ \n",
              "                                                     input_ICMP_TYPE[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                                                     input_PROTOCOL[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                                                     input_SERVER_TCP \n",
              "                                                     input_L4_DST_POR \n",
              "                                                     input_L7_PROTO[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " embed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span>  feature_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " block_0_transforme  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">83,200</span>  embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode</span>                                                   \n",
              "\n",
              " block_1_transforme  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">83,200</span>  block_0_transfor \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode</span>                                                   \n",
              "\n",
              " slice_last (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  block_1_transfor \n",
              "\n",
              " classification_mlp  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span>  slice_last[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                               \n",
              "\n",
              " dropout_23           (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  classification_m \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                                                             \n",
              "\n",
              " multiclass_classif  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span>  dropout_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                               \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m193,226\u001b[0m (754.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193,226</span> (754.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m193,226\u001b[0m (754.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">193,226</span> (754.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building eval dataset...\n",
            "Splitting dataset to featurewise...\n",
            "Evaluation dataset is built!\n",
            "Evaluation dataset size: 239027\n",
            "Label: Analysis(0)\n",
            "Positive samples in eval set: 348\n",
            "Negative samples in eval set: 238679\n",
            "Label: Backdoor(1)\n",
            "Positive samples in eval set: 375\n",
            "Negative samples in eval set: 238652\n",
            "Label: Benign(2)\n",
            "Positive samples in eval set: 222756\n",
            "Negative samples in eval set: 16271\n",
            "Label: DoS(3)\n",
            "Positive samples in eval set: 983\n",
            "Negative samples in eval set: 238044\n",
            "Label: Exploits(4)\n",
            "Positive samples in eval set: 5630\n",
            "Negative samples in eval set: 233397\n",
            "Label: Fuzzers(5)\n",
            "Positive samples in eval set: 3566\n",
            "Negative samples in eval set: 235461\n",
            "Label: Generic(6)\n",
            "Positive samples in eval set: 2822\n",
            "Negative samples in eval set: 236205\n",
            "Label: Reconnaissance(7)\n",
            "Positive samples in eval set: 2267\n",
            "Negative samples in eval set: 236760\n",
            "Label: Shellcode(8)\n",
            "Positive samples in eval set: 249\n",
            "Negative samples in eval set: 238778\n",
            "Label: Worms(9)\n",
            "Positive samples in eval set: 31\n",
            "Negative samples in eval set: 238996\n",
            "Epoch = 0 / 5 (early stop in 5), step = 0, loss = 2.30074, results = [array(2.3007436, dtype=float32), array(0.1640625, dtype=float32)] -- elapsed (train): 0.00s\n",
            "Epoch = 0 / 5 (early stop in 5), step = 10, loss = 1.47298, results = [array(1.4729759, dtype=float32), array(0.52627844, dtype=float32)] -- elapsed (train): 1.15s\n",
            "Epoch = 0 / 5 (early stop in 5), step = 24, loss = 1.13694, results = [array(1.1369394, dtype=float32), array(0.638125, dtype=float32)] -- elapsed (train): 2.24s\n",
            "Epoch = 0 / 5 (early stop in 5), step = 39, loss = 0.96084, results = [array(0.9608361, dtype=float32), array(0.69492185, dtype=float32)] -- elapsed (train): 3.38s\n",
            "Epoch = 0 / 5 (early stop in 5), step = 53, loss = 0.85332, results = [array(0.8533193, dtype=float32), array(0.7332176, dtype=float32)] -- elapsed (train): 4.56s\n",
            "Epoch = 0 / 5 (early stop in 5), step = 61, loss = 0.80407, results = [array(0.8040659, dtype=float32), array(0.750126, dtype=float32)] -- elapsed (train): 5.60s\n",
            "Epoch = 1 / 5 (early stop in 5), step = 10, loss = 0.74704, results = [array(0.74704397, dtype=float32), array(0.7679167, dtype=float32)] -- elapsed (train): 6.69s\n",
            "Epoch = 1 / 5 (early stop in 5), step = 25, loss = 0.69964, results = [array(0.69963664, dtype=float32), array(0.78315973, dtype=float32)] -- elapsed (train): 7.88s\n",
            "Epoch = 1 / 5 (early stop in 5), step = 40, loss = 0.66091, results = [array(0.6609105, dtype=float32), array(0.7951637, dtype=float32)] -- elapsed (train): 9.02s\n",
            "Epoch = 1 / 5 (early stop in 5), step = 51, loss = 0.63951, results = [array(0.63951254, dtype=float32), array(0.8021956, dtype=float32)] -- elapsed (train): 10.13s\n",
            "Epoch = 1 / 5 (early stop in 5), step = 61, loss = 0.62672, results = [array(0.6267216, dtype=float32), array(0.8058036, dtype=float32)] -- elapsed (train): 11.20s\n",
            "Epoch = 2 / 5 (early stop in 5), step = 11, loss = 0.60516, results = [array(0.6051615, dtype=float32), array(0.81177455, dtype=float32)] -- elapsed (train): 12.25s\n",
            "Epoch = 2 / 5 (early stop in 5), step = 26, loss = 0.58507, results = [array(0.58506733, dtype=float32), array(0.81789315, dtype=float32)] -- elapsed (train): 13.38s\n",
            "Epoch = 2 / 5 (early stop in 5), step = 40, loss = 0.56779, results = [array(0.5677888, dtype=float32), array(0.82239276, dtype=float32)] -- elapsed (train): 14.51s\n",
            "Epoch = 2 / 5 (early stop in 5), step = 49, loss = 0.55823, results = [array(0.5582326, dtype=float32), array(0.82500875, dtype=float32)] -- elapsed (train): 15.67s\n",
            "Epoch = 2 / 5 (early stop in 5), step = 62, loss = 0.54560, results = [array(0.54559535, dtype=float32), array(0.828534, dtype=float32)] -- elapsed (train): 16.78s\n",
            "Epoch = 3 / 5 (early stop in 5), step = 13, loss = 0.53428, results = [array(0.5342756, dtype=float32), array(0.831652, dtype=float32)] -- elapsed (train): 17.96s\n",
            "Epoch = 3 / 5 (early stop in 5), step = 28, loss = 0.52260, results = [array(0.5226044, dtype=float32), array(0.83523047, dtype=float32)] -- elapsed (train): 19.11s\n",
            "Epoch = 3 / 5 (early stop in 5), step = 39, loss = 0.51504, results = [array(0.51503634, dtype=float32), array(0.8372508, dtype=float32)] -- elapsed (train): 20.23s\n",
            "Epoch = 3 / 5 (early stop in 5), step = 49, loss = 0.50777, results = [array(0.50776523, dtype=float32), array(0.8391335, dtype=float32)] -- elapsed (train): 21.31s\n",
            "Epoch = 4 / 5 (early stop in 5), step = 0, loss = 0.49959, results = [array(0.49958748, dtype=float32), array(0.84150046, dtype=float32)] -- elapsed (train): 22.45s\n",
            "Epoch = 4 / 5 (early stop in 5), step = 14, loss = 0.49104, results = [array(0.4910364, dtype=float32), array(0.84377885, dtype=float32)] -- elapsed (train): 23.51s\n",
            "Epoch = 4 / 5 (early stop in 5), step = 28, loss = 0.48328, results = [array(0.483279, dtype=float32), array(0.8461897, dtype=float32)] -- elapsed (train): 24.62s\n",
            "Epoch = 4 / 5 (early stop in 5), step = 37, loss = 0.47920, results = [array(0.4792022, dtype=float32), array(0.84736395, dtype=float32)] -- elapsed (train): 25.78s\n",
            "Epoch = 4 / 5 (early stop in 5), step = 50, loss = 0.47328, results = [array(0.4732766, dtype=float32), array(0.8492213, dtype=float32)] -- elapsed (train): 26.84s\n",
            "\u001b[1m7470/7470\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 13ms/step\n",
            "Epoch 4 yielded predictions: (239027,)\n",
            "[Analysis -- overall balanced accuracy: 74.82%, TP = 173 / 348, TN = 238,523 / 238,679\n",
            "[Backdoor -- overall balanced accuracy: 75.17%, TP = 189 / 375, TN = 238,512 / 238,652\n",
            "[Benign -- overall balanced accuracy: 99.33%, TP = 220,265 / 222,756, TN = 16,236 / 16,271\n",
            "[DoS -- overall balanced accuracy: 61.56%, TP = 228 / 983, TN = 237,875 / 238,044\n",
            "[Exploits -- overall balanced accuracy: 94.56%, TP = 5,078 / 5,630, TN = 230,873 / 233,397\n",
            "[Fuzzers -- overall balanced accuracy: 95.51%, TP = 3,265 / 3,566, TN = 234,196 / 235,461\n",
            "[Generic -- overall balanced accuracy: 89.88%, TP = 2,256 / 2,822, TN = 235,771 / 236,205\n",
            "[Reconnaissance -- overall balanced accuracy: 88.83%, TP = 1,765 / 2,267, TN = 236,290 / 236,760\n",
            "[Shellcode -- overall balanced accuracy: 90.07%, TP = 200 / 249, TN = 238,363 / 238,778\n",
            "[Worms -- overall balanced accuracy: 50.00%, TP = 0 / 31, TN = 238,996 / 238,996\n"
          ]
        }
      ]
    }
  ]
}