{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**DSCI 565: Semester Project**\n",
        "\n",
        "Reference Paper:\n",
        "\n",
        "FlowTransformer: A Transformer Framework for Flow-based Network Intrusion Detection Systems\n",
        "\n",
        "Dataset:\n",
        "\n",
        "Towards a Standard Feature Set for Network Intrusion Detection System Datasets (NetFlow-v2)\n",
        "\n",
        "https://staff.itee.uq.edu.au/marius/NIDS_datasets/\n",
        "\n",
        "NF-UNSW-NB15-v2, NF-CSE-CIC-IDS2018-v2\n",
        "\n",
        "Keyword: REQ"
      ],
      "metadata": {
        "id": "0v920que-00p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaoMzTnmHmWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c464c05-2e71-4b75-8899-c32769d2310e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, sys\n",
        "# framework library\n",
        "# https://github.com/liamdm/FlowTransformer\n",
        "path = \"/content/drive/MyDrive/\"\n",
        "\n",
        "if path not in sys.path:\n",
        "    sys.path.append(path)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from typing import Tuple, List, Dict, Any, Optional\n",
        "from enum import Enum\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "try:\n",
        "    from tensorflow._api.v2.v2 import keras\n",
        "except ImportError:\n",
        "    from tensorflow import keras\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras.layers as layers\n",
        "from keras.layers import Embedding, Dense, Layer, MultiHeadAttention, Dropout, LayerNormalization, Conv1D, Concatenate, Reshape, Flatten, Lambda, GlobalAveragePooling1D\n",
        "\n",
        "# FlowTransformer framework\n",
        "from framework.base_preprocessing import BasePreProcessing\n",
        "from framework.enumerations import CategoricalFormat\n",
        "from framework.base_input_encoding import BaseInputEncoding\n",
        "from framework.base_classification_head import BaseClassificationHead\n",
        "from framework.base_sequential import BaseSequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = path + \"data/\"\n",
        "feature = \"NetFlow_v2_Features.csv\"\n",
        "datasets = [\"NF-CSE-CIC-IDS2018-v2/NF-CSE-CIC-IDS2018-v2.csv\", \"NF-UNSW-NB15-v2/NF-UNSW-NB15-v2.csv\"]\n",
        "\n",
        "!wc -l drive/MyDrive/data/NetFlow_v2_Features.csv\n",
        "!wc -l drive/MyDrive/data/NF-CSE-CIC-IDS2018-v2/NF-CSE-CIC-IDS2018-v2.csv\n",
        "!wc -l drive/MyDrive/data/NF-UNSW-NB15-v2/NF-UNSW-NB15-v2.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmOVSlqusz9j",
        "outputId": "e6625a53-a35f-490b-f445-58afe5700ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44 drive/MyDrive/data/NetFlow_v2_Features.csv\n",
            "18893709 drive/MyDrive/data/NF-CSE-CIC-IDS2018-v2/NF-CSE-CIC-IDS2018-v2.csv\n",
            "2390276 drive/MyDrive/data/NF-UNSW-NB15-v2/NF-UNSW-NB15-v2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implementation**"
      ],
      "metadata": {
        "id": "8Y6y5_Re95Iz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NetFlow Collector & Pre-processing"
      ],
      "metadata": {
        "id": "AExZFUoJW8xu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NetFlow Collector\n",
        "# REQ\n",
        "\n",
        "# Pre-precessing\n",
        "# https://github.com/liamdm/FlowTransformer/blob/master/implementations/pre_processings.py\n",
        "class StandardPreProcessing(BasePreProcessing):\n",
        "    def __init__(self, n_categorical_levels: int, clip_numerical_values:bool=False):\n",
        "        super().__init__()\n",
        "        self.n_categorical_levels:int = n_categorical_levels\n",
        "        self.clip_numerical_values:bool = clip_numerical_values\n",
        "        self.min_range = {}\n",
        "        self.encoded_levels = {}\n",
        "\n",
        "    @property\n",
        "    def name(self) -> str:\n",
        "        return \"Standard Preprocessing\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self) -> dict:\n",
        "        return {\n",
        "            \"n_categorical_levels\": self.n_categorical_levels,\n",
        "            \"clip_numerical_values\": self.clip_numerical_values\n",
        "        }\n",
        "\n",
        "    def fit_numerical(self, column_name: str, values: np.array):\n",
        "\n",
        "        v0 = np.min(values)\n",
        "        v1 = np.max(values)\n",
        "        r = v1 - v0\n",
        "\n",
        "        self.min_range[column_name] = (v0, r)\n",
        "\n",
        "    def transform_numerical(self, column_name: str, values: np.array):\n",
        "        col_min, col_range = self.min_range[column_name]\n",
        "\n",
        "        if col_range == 0:\n",
        "            return np.zeros_like(values, dtype=\"float32\")\n",
        "\n",
        "        # center on zero\n",
        "        values -= col_min\n",
        "\n",
        "        # apply a logarithm\n",
        "        col_values = np.log(values + 1)\n",
        "\n",
        "        # scale max to 1\n",
        "        col_values *= 1. / np.log(col_range + 1)\n",
        "\n",
        "        if self.clip_numerical_values:\n",
        "            col_values = np.clip(col_values, 0., 1.)\n",
        "\n",
        "        return col_values\n",
        "\n",
        "    def fit_categorical(self, column_name: str, values: np.array):\n",
        "        levels, level_counts = np.unique(values, return_counts=True)\n",
        "        sorted_levels = list(sorted(zip(levels, level_counts), key=lambda x: x[1], reverse=True))\n",
        "        self.encoded_levels[column_name] = [s[0] for s in sorted_levels[:self.n_categorical_levels]]\n",
        "\n",
        "\n",
        "    def transform_categorical(self, column_name:str, values: np.array, expected_categorical_format: CategoricalFormat):\n",
        "        encoded_levels = self.encoded_levels[column_name]\n",
        "        print(f\"Encoding the {len(encoded_levels)} levels for {column_name}\")\n",
        "\n",
        "        result_values = np.ones(len(values), dtype=\"uint32\")\n",
        "        for level_i, level in enumerate(encoded_levels):\n",
        "            level_mask = values == level\n",
        "\n",
        "            # we use +1 here, as 0 = previously unseen, and 1 to (n + 1) are the encoded levels\n",
        "            result_values[level_mask] = level_i + 1\n",
        "\n",
        "        if expected_categorical_format == CategoricalFormat.Integers:\n",
        "            return result_values\n",
        "\n",
        "        v = pd.get_dummies(result_values, prefix=column_name)\n",
        "        return v"
      ],
      "metadata": {
        "id": "dWX1zO9YW-lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FlowTransformer Framework"
      ],
      "metadata": {
        "id": "iGZ6bAcYXAEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Encoder\n",
        "# ref: https://github.com/liamdm/FlowTransformer/blob/master/implementations/input_encodings.py\n",
        "class NoInputEncoder(BaseInputEncoding):\n",
        "    def apply(self, X, prefix:str=None):\n",
        "\n",
        "        numerical_feature_inputs = X[:self.model_input_specification.n_numeric_features]\n",
        "        categorical_feature_inputs = X[self.model_input_specification.n_numeric_features:]\n",
        "\n",
        "        if self.model_input_specification.categorical_format == CategoricalFormat.Integers:\n",
        "            warnings.warn(\"It doesn't make sense to be using integer based inputs without encoding!\")\n",
        "            categorical_feature_inputs = [Lambda(lambda x: tf.cast(x, tf.float32))(c) for c in categorical_feature_inputs]\n",
        "\n",
        "        concat = Concatenate()(numerical_feature_inputs + categorical_feature_inputs)\n",
        "\n",
        "        return concat\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "        return \"No Input Encoding\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self):\n",
        "        return {}\n",
        "\n",
        "    @property\n",
        "    def required_input_format(self) -> CategoricalFormat:\n",
        "        return CategoricalFormat.OneHot\n",
        "\n",
        "class EmbedLayerType(Enum):\n",
        "    Dense = 0,\n",
        "    Lookup = 1,\n",
        "    Projection = 2\n",
        "\n",
        "class RecordLevelEmbed(BaseInputEncoding):\n",
        "    def __init__(self, embed_dimension: int, project:bool = False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embed_dimension: int = embed_dimension\n",
        "        self.project: bool = project\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "        if self.project:\n",
        "            return \"Record Level Projection\"\n",
        "        return \"Record Level Embedding\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self):\n",
        "        return {\n",
        "            \"dimensions_per_feature\": self.embed_dimension\n",
        "        }\n",
        "\n",
        "    def apply(self, X:List[keras.Input], prefix: str = None):\n",
        "        if prefix is None:\n",
        "            prefix = \"\"\n",
        "\n",
        "        assert self.model_input_specification.categorical_format == CategoricalFormat.OneHot\n",
        "\n",
        "        x = Concatenate(name=f\"{prefix}feature_concat\", axis=-1)(X)\n",
        "        x = Dense(self.embed_dimension, activation=\"linear\", use_bias=not self.project, name=f\"{prefix}embed\")(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def required_input_format(self) -> CategoricalFormat:\n",
        "        return CategoricalFormat.OneHot\n",
        "\n",
        "class CategoricalFeatureEmbed(BaseInputEncoding):\n",
        "    def __init__(self, embed_layer_type: EmbedLayerType, dimensions_per_feature: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dimensions_per_feature: int = dimensions_per_feature\n",
        "        self.embed_layer_type: EmbedLayerType = embed_layer_type\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "        if self.embed_layer_type == EmbedLayerType.Dense:\n",
        "            return f\"Categorical Feature Embed - Dense\"\n",
        "        elif self.embed_layer_type == EmbedLayerType.Lookup:\n",
        "            return f\"Categorical Feature Embed - Lookup\"\n",
        "        elif self.embed_layer_type == EmbedLayerType.Projection:\n",
        "            return f\"Categorical Feature Embed - Projection\"\n",
        "        raise RuntimeError()\n",
        "\n",
        "    @property\n",
        "    def parameters(self):\n",
        "        return {\n",
        "            \"dimensions_per_feature\": self.dimensions_per_feature\n",
        "        }\n",
        "\n",
        "    def apply(self, X:List[keras.Input], prefix:str=None):\n",
        "        if prefix is None:\n",
        "            prefix = \"\"\n",
        "\n",
        "        if self.model_input_specification is None:\n",
        "            raise Exception(\"Please call build() before calling apply!\")\n",
        "\n",
        "        numerical_feature_inputs = X[:self.model_input_specification.n_numeric_features]\n",
        "        categorical_feature_inputs = X[self.model_input_specification.n_numeric_features:]\n",
        "\n",
        "        #print(len(numerical_feature_inputs), len(categorical_feature_inputs))\n",
        "        #print(len(self.model_input_specification.categorical_feature_names), self.model_input_specification.categorical_feature_names)\n",
        "\n",
        "        collected_numeric = Concatenate(name=f\"{prefix}concat_numeric\")(numerical_feature_inputs)\n",
        "\n",
        "        collected_categorical = []\n",
        "        for categorical_field_i, categorical_field_name in enumerate(self.model_input_specification.categorical_feature_names):\n",
        "            cat_field_x = categorical_feature_inputs[categorical_field_i]\n",
        "            if self.embed_layer_type != EmbedLayerType.Lookup:\n",
        "                assert self.model_input_specification.categorical_format == CategoricalFormat.OneHot\n",
        "\n",
        "                x = Dense(self.dimensions_per_feature,\n",
        "                          activation=\"linear\",\n",
        "                          use_bias=(self.embed_layer_type == EmbedLayerType.Dense),\n",
        "                          name=f\"{prefix}embed_{categorical_field_name.replace('/', '')}\")(cat_field_x)\n",
        "                collected_categorical.append(x)\n",
        "\n",
        "            elif self.embed_layer_type == EmbedLayerType.Lookup:\n",
        "                assert self.model_input_specification.categorical_format == CategoricalFormat.Integers\n",
        "\n",
        "                # reshape the sequence to a flat array\n",
        "                x = cat_field_x\n",
        "                x = Embedding(input_dim=self.model_input_specification.levels_per_categorical_feature[categorical_field_i] + 1, output_dim=self.dimensions_per_feature, input_length=self.sequence_length)(x)\n",
        "                x = Reshape((self.sequence_length, self.dimensions_per_feature), name=f\"{prefix}expand_{categorical_field_name}\")(x)\n",
        "\n",
        "                collected_categorical.append(x)\n",
        "        collected_categorical = Concatenate(name=f\"{prefix}concat_categorical\")(collected_categorical)\n",
        "\n",
        "        collected = Concatenate()([collected_numeric, collected_categorical])\n",
        "\n",
        "        return collected\n",
        "\n",
        "    @property\n",
        "    def required_input_format(self) -> CategoricalFormat:\n",
        "        return CategoricalFormat.Integers if self.embed_layer_type == EmbedLayerType.Lookup else CategoricalFormat.OneHot\n",
        "\n",
        "# Transformer Models\n",
        "\n",
        "# Decoder Block\n",
        "# ref: https://github.com/liamdm/FlowTransformer/blob/master/implementations/transformers/basic/decoder_block.py\n",
        "class TransformerDecoderBlock(Layer):\n",
        "    def __init__(self, input_dimension:int, inner_dimension:int, num_heads:int, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.input_dimension = input_dimension\n",
        "        self.inner_dimension = inner_dimension\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=input_dimension)\n",
        "        self.dropout1 = Dropout(dropout_rate)\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.ffn = tf.keras.Sequential([\n",
        "            Dense(inner_dimension, activation='relu'),\n",
        "            Dense(input_dimension)\n",
        "        ])\n",
        "        self.dropout2 = Dropout(dropout_rate)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    # noinspection PyMethodOverriding\n",
        "    # SIAN\n",
        "    def call(self, inputs, training=True, mask=None):\n",
        "        # inputs = (target_seq, enc_output)\n",
        "        target_seq = inputs\n",
        "        enc_output = inputs\n",
        "\n",
        "        # self attention of target_seq\n",
        "        attn_output = self.mha(target_seq, target_seq)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = target_seq + attn_output\n",
        "        out1 = self.layernorm1(out1)\n",
        "\n",
        "        # multi-head attention with encoder output as the key and value, and target_seq as the query\n",
        "        attn_output = self.mha(out1, enc_output)\n",
        "        attn_output = self.dropout2(attn_output, training=training)\n",
        "        out2 = out1 + attn_output\n",
        "        out2 = self.layernorm2(out2)\n",
        "\n",
        "        # feed forward network\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out3 = out2 + ffn_output\n",
        "        out3 = self.layernorm2(out3)\n",
        "\n",
        "        return out3\n",
        "\n",
        "# Encoder Block\n",
        "# ref: https://github.com/liamdm/FlowTransformer/blob/master/implementations/transformers/basic/encoder_block.py\n",
        "class GPT3Attention(layers.Layer):\n",
        "    def __init__(self, n_heads, d_model, dropout_rate=0.1):\n",
        "        super(GPT3Attention, self).__init__()\n",
        "        self.n_heads = n_heads\n",
        "        self.d_model = d_model\n",
        "        self.depth = d_model // n_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.n_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # noinspection PyMethodOverriding\n",
        "    def call(self, q, k, v, mask=None):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        # Scaled Dot-Product Attention\n",
        "        scaled_attention_logits = tf.matmul(q, k, transpose_b=True)\n",
        "        scaled_attention_logits = scaled_attention_logits / tf.math.sqrt(tf.cast(self.depth, tf.float32))\n",
        "\n",
        "        if mask is not None:\n",
        "            scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "        attention_weights = self.dropout(attention_weights)\n",
        "\n",
        "        output = tf.matmul(attention_weights, v)\n",
        "        output = tf.transpose(output, perm=[0, 2, 1, 3])\n",
        "        output = tf.reshape(output, (batch_size, -1, self.d_model))\n",
        "\n",
        "        output = self.dense(output)\n",
        "        output = self.dropout(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "class MultiHeadAttentionImplementation:\n",
        "    Keras = 0,\n",
        "    GPT3 = 1\n",
        "\n",
        "class TransformerEncoderBlock(layers.Layer):\n",
        "    def __init__(self, input_dimension:int, inner_dimension:int, num_heads:int, dropout_rate=0.1, use_conv:bool=False, prefix:str=None, attn_implementation:MultiHeadAttentionImplementation = MultiHeadAttentionImplementation.Keras):\n",
        "\n",
        "        if prefix is None:\n",
        "            prefix = \"\"\n",
        "\n",
        "        super().__init__(name=f\"{prefix}transformer_encoder\")\n",
        "\n",
        "        if inner_dimension < input_dimension:\n",
        "            warnings.warn(f\"Typically inner_dimension should be greater than or equal to the input_dimension!\")\n",
        "\n",
        "        self.attn_implementation = attn_implementation\n",
        "\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.attention = \\\n",
        "            layers.MultiHeadAttention(num_heads=num_heads, key_dim=inner_dimension, name=f\"{prefix}multi_head_attn\") \\\n",
        "                if attn_implementation == MultiHeadAttentionImplementation.Keras else\\\n",
        "                GPT3Attention(num_heads, inner_dimension, dropout_rate=0.0)\n",
        "\n",
        "        layer_norm = 1e-6\n",
        "\n",
        "        self.attention_dropout = layers.Dropout(dropout_rate, name=f\"{prefix}attention_dropout\")\n",
        "        self.attention_layer_norm = layers.LayerNormalization(epsilon=layer_norm, name=f\"{prefix}attention_layer_norm\")\n",
        "\n",
        "        self.feed_forward_0 = Conv1D(filters=inner_dimension, kernel_size=1, activation=\"relu\", name=f\"{prefix}feed_forward_0\") \\\n",
        "            if use_conv else Dense(inner_dimension, activation=\"relu\", name=f\"{prefix}feed_forward_0\")\n",
        "        self.feed_forward_1 = Conv1D(filters=input_dimension, kernel_size=1, activation=\"relu\", name=f\"{prefix}feed_forward_1\") \\\n",
        "            if use_conv else Dense(input_dimension, activation=\"relu\", name=f\"{prefix}feed_forward_1\")\n",
        "\n",
        "        self.feed_forward_dropout = layers.Dropout(dropout_rate, name=f\"{prefix}feed_forward_dropout\")\n",
        "        self.feed_forward_layer_norm = layers.LayerNormalization(epsilon=layer_norm, name=f\"{prefix}feed_forward_layer_norm\")\n",
        "\n",
        "    # noinspection PyMethodOverriding\n",
        "    # SIAN\n",
        "    def call(self, inputs, training=True, mask=None):\n",
        "        x = inputs\n",
        "        x = self.attention(x, x) if self.attn_implementation == MultiHeadAttentionImplementation.Keras else self.attention(x, x, x, mask)\n",
        "\n",
        "        attention_output = self.attention_dropout(x, training=training) if self.dropout_rate > 0 else x\n",
        "\n",
        "        x = inputs + attention_output\n",
        "        x = self.attention_layer_norm(x)\n",
        "        x = self.feed_forward_0(x)\n",
        "        x = self.feed_forward_1(x)\n",
        "        x = self.feed_forward_dropout(x, training=training) if self.dropout_rate > 0 else x\n",
        "        feed_forward_output = x\n",
        "\n",
        "        return self.feed_forward_layer_norm(attention_output + feed_forward_output)\n",
        "\n",
        "# Basic Transformers\n",
        "# ref: https://github.com/liamdm/FlowTransformer/blob/master/implementations/transformers/basic_transformers.py\n",
        "class BasicTransformer(BaseSequential):\n",
        "\n",
        "    @property\n",
        "    def name(self) -> str:\n",
        "        if self.use_conv:\n",
        "            return f\"Basic Conv Transformer\" + (\" Decoder\" if self.is_decoder else \"\")\n",
        "        else:\n",
        "            return f\"Basic Dense Transformer\" + (\" Decoder\" if self.is_decoder else \"\")\n",
        "\n",
        "    @property\n",
        "    def parameters(self) -> dict:\n",
        "        return {\n",
        "            \"n_layers\": self.n_layers,\n",
        "            \"internal_size\": self.internal_size,\n",
        "            \"use_conv\": self.use_conv,\n",
        "            \"n_heads\": self.n_heads,\n",
        "            \"dropout_rate\": self.dropout_rate,\n",
        "            \"head_size\": self.internal_size\n",
        "        }\n",
        "\n",
        "    def __init__(self, n_layers:int, internal_size:int, n_heads:int, use_conv:bool=False, dropout_rate:float=0.1, is_decoder=False):\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.internal_size = internal_size\n",
        "        self.use_conv = use_conv\n",
        "        self.n_heads = n_heads\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.is_decoder = is_decoder\n",
        "\n",
        "    def apply(self, X, prefix: str = None):\n",
        "        #window_size = self.sequence_length\n",
        "        real_size = X.shape[-1]\n",
        "\n",
        "        m_x = X\n",
        "\n",
        "        for layer_i in range(self.n_layers):\n",
        "            if self.is_decoder:\n",
        "                if self.use_conv:\n",
        "                    raise NotImplementedError()\n",
        "                m_x = TransformerDecoderBlock(real_size, self.internal_size, self.n_heads, dropout_rate=self.dropout_rate)(m_x)\n",
        "            else:\n",
        "                m_x = TransformerEncoderBlock(real_size, self.internal_size, self.n_heads, dropout_rate=self.dropout_rate, use_conv=self.use_conv, prefix=f\"{prefix}block_{layer_i}_\")(m_x)\n",
        "\n",
        "        return m_x\n",
        "\n",
        "# Named Transformers\n",
        "# ref: https://github.com/liamdm/FlowTransformer/blob/master/implementations/transformers/named_transformers.py\n",
        "class GPTSmallTransformer(BaseSequential):\n",
        "\n",
        "    @property\n",
        "    def name(self) -> str:\n",
        "        return \"GPT Model\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self) -> dict:\n",
        "        return {\n",
        "            \"n_layers\": self.n_layers,\n",
        "            \"internal_size\": self.internal_size,\n",
        "            \"n_heads\": self.n_heads,\n",
        "            \"dropout_rate\": self.dropout_rate,\n",
        "            \"head_size\": self.head_size\n",
        "        }\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.n_layers = 12\n",
        "        self.internal_size = 768\n",
        "        self.n_heads = 12\n",
        "        self.head_size = self.internal_size / self.n_heads\n",
        "        self.dropout_rate = 0.02\n",
        "        self.is_decoder = True\n",
        "\n",
        "    def apply(self, X, prefix: str = None):\n",
        "        #window_size = self.sequence_length\n",
        "        real_size = X.shape[-1]\n",
        "\n",
        "        m_x = X\n",
        "\n",
        "        for layer_i in range(self.n_layers):\n",
        "            m_x = TransformerDecoderBlock(real_size, self.internal_size, self.n_heads, dropout_rate=self.dropout_rate)(m_x)\n",
        "\n",
        "        return m_x\n",
        "\n",
        "\n",
        "class BERTSmallTransformer(BaseSequential):\n",
        "\n",
        "    @property\n",
        "    def name(self) -> str:\n",
        "        return \"BERT Model\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self) -> dict:\n",
        "        return {\n",
        "            \"n_layers\": self.n_layers,\n",
        "            \"internal_size\": self.internal_size,\n",
        "            \"n_heads\": self.n_heads,\n",
        "            \"dropout_rate\": self.dropout_rate,\n",
        "            \"head_size\": self.head_size\n",
        "        }\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.n_layers = 12\n",
        "        self.internal_size = 768\n",
        "        self.n_heads = 12\n",
        "        self.head_size = self.internal_size / self.n_heads\n",
        "        self.dropout_rate = 0.02\n",
        "        self.is_decoder = False\n",
        "\n",
        "    def apply(self, X, prefix: str = None):\n",
        "        #window_size = self.sequence_length\n",
        "        real_size = X.shape[-1]\n",
        "\n",
        "        m_x = X\n",
        "\n",
        "        for layer_i in range(self.n_layers):\n",
        "            m_x = TransformerEncoderBlock(real_size, self.internal_size, self.n_heads, dropout_rate=self.dropout_rate, prefix=f\"block_{layer_i}_\")(m_x)\n",
        "\n",
        "        return m_x\n",
        "\n",
        "# Classficiation Head\n",
        "# ref: https://github.com/liamdm/FlowTransformer/blob/master/implementations/classification_heads.py\n",
        "class FlattenClassificationHead(BaseClassificationHead):\n",
        "    def apply(self, X, prefix: str = None):\n",
        "        if prefix is None:\n",
        "            prefix = \"\"\n",
        "        x = Flatten(name=f\"{prefix}flatten\")(X)\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def name(self) -> str:\n",
        "        return \"Flatten\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self) -> dict:\n",
        "        return {}\n",
        "\n",
        "\n",
        "class FeaturewiseEmbedding(BaseClassificationHead):\n",
        "    def __init__(self, project:bool=False):\n",
        "        super().__init__()\n",
        "        self.project: bool = project\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "        if self.project:\n",
        "            return f\"Featurewise Embed - Projection\"\n",
        "        else:\n",
        "            return f\"Featurewise Embed - Dense\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self):\n",
        "        return {}\n",
        "\n",
        "\n",
        "    def apply(self, X, prefix:str=None):\n",
        "        if prefix is None:\n",
        "            prefix = \"\"\n",
        "\n",
        "        if self.model_input_specification is None:\n",
        "            raise Exception(\"Please call build() before calling apply!\")\n",
        "\n",
        "        x = Dense(1,\n",
        "                  activation=\"linear\",\n",
        "                  use_bias=(not self.project),\n",
        "                  name=f\"{prefix}featurewise_embed\")(X)\n",
        "\n",
        "        x = Flatten()(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class GlobalAveragePoolingClassificationHead(BaseClassificationHead):\n",
        "    def apply(self, X, prefix: str = None):\n",
        "        if prefix is None:\n",
        "            prefix = \"\"\n",
        "        return GlobalAveragePooling1D(name=f\"{prefix}global_avg_pooling_1d\")(X)\n",
        "\n",
        "    @property\n",
        "    def name(self) -> str:\n",
        "        return \"Global Average Pooling\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self) -> dict:\n",
        "        return {}\n",
        "\n",
        "\n",
        "class LastTokenClassificationHead(BaseClassificationHead):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def apply(self, X, prefix: str = None):\n",
        "        if prefix is None:\n",
        "            prefix = \"\"\n",
        "\n",
        "        x = Lambda(lambda x: x[..., -1, :], name=f\"{prefix}slice_last\")(X)\n",
        "        #x = Flatten(name=f\"{prefix}flatten_last\")(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def name(self) -> str:\n",
        "        return \"Last Token\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self) -> dict:\n",
        "        return {}\n",
        "\n",
        "\n",
        "class CLSTokenClassificationHead(LastTokenClassificationHead):\n",
        "\n",
        "\n",
        "    @property\n",
        "    def name(self) -> str:\n",
        "        return \"CLS Token\"\n",
        "\n",
        "    @property\n",
        "    def parameters(self) -> dict:\n",
        "        return {}\n",
        "\n",
        "    def apply_before_transformer(self, X, prefix: str = None):\n",
        "        if prefix is None:\n",
        "            prefix = \"\"\n",
        "\n",
        "        window_size = self.sequence_length\n",
        "\n",
        "        x = X\n",
        "        batch_size = tf.shape(x)[0]\n",
        "        flow_size = tf.shape(x)[2]\n",
        "\n",
        "        cls_token_horizontal_single = np.zeros((window_size + 1,))\n",
        "        cls_token_horizontal_single[-1] = 1.\n",
        "        cls_token_horizontal_single = tf.convert_to_tensor(cls_token_horizontal_single, dtype=tf.float32)\n",
        "\n",
        "        cls_token_horizontal = tf.ones((batch_size, window_size + 1,), dtype=tf.float32)\n",
        "        cls_token_horizontal = tf.multiply(cls_token_horizontal, cls_token_horizontal_single)\n",
        "        cls_token_horizontal = tf.expand_dims(cls_token_horizontal, axis=-1)\n",
        "\n",
        "        cls_token_vertical = tf.zeros((batch_size, 1, flow_size,), dtype=tf.float32)\n",
        "\n",
        "        x = Concatenate(axis=-2, name=f'{prefix}cls_vertical')([x, cls_token_vertical])\n",
        "        x = Concatenate(axis=-1, name=f'{prefix}cls_horizontal')([x, cls_token_horizontal])\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "m8-2xeP8XGiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Demonstration**\n",
        "\n",
        "ref:\n",
        "\n",
        "https://github.com/liamdm/FlowTransformer/blob/master/demonstration.ipynb\n",
        "\n",
        "https://github.com/liamdm/FlowTransformer/blob/master/FlowTransformer_demo.ipynb"
      ],
      "metadata": {
        "id": "xIZu030l-FA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demonstration_folder = \"demonstration\"\n",
        "\n",
        "if not os.path.exists(demonstration_folder):\n",
        "    os.mkdir(demonstration_folder)\n",
        "\n",
        "from framework.dataset_specification import DatasetSpecification\n",
        "flow_format = DatasetSpecification(\n",
        "        include_fields=['NUM_PKTS_UP_TO_128_BYTES', 'SRC_TO_DST_SECOND_BYTES', 'OUT_PKTS', 'OUT_BYTES', 'NUM_PKTS_128_TO_256_BYTES', 'DST_TO_SRC_AVG_THROUGHPUT', 'DURATION_IN', 'L4_SRC_PORT', 'ICMP_TYPE', 'PROTOCOL', 'SERVER_TCP_FLAGS', 'IN_PKTS', 'NUM_PKTS_512_TO_1024_BYTES', 'CLIENT_TCP_FLAGS', 'TCP_WIN_MAX_IN', 'NUM_PKTS_256_TO_512_BYTES', 'SHORTEST_FLOW_PKT', 'MIN_IP_PKT_LEN', 'LONGEST_FLOW_PKT', 'L4_DST_PORT', 'MIN_TTL', 'DST_TO_SRC_SECOND_BYTES', 'NUM_PKTS_1024_TO_1514_BYTES', 'DURATION_OUT', 'FLOW_DURATION_MILLISECONDS', 'TCP_FLAGS', 'MAX_TTL', 'SRC_TO_DST_AVG_THROUGHPUT', 'ICMP_IPV4_TYPE', 'MAX_IP_PKT_LEN', 'RETRANSMITTED_OUT_BYTES', 'IN_BYTES', 'RETRANSMITTED_IN_BYTES', 'TCP_WIN_MAX_OUT', 'L7_PROTO', 'RETRANSMITTED_OUT_PKTS', 'RETRANSMITTED_IN_PKTS'],\n",
        "        categorical_fields=['CLIENT_TCP_FLAGS', 'L4_SRC_PORT', 'TCP_FLAGS', 'ICMP_IPV4_TYPE', 'ICMP_TYPE', 'PROTOCOL', 'SERVER_TCP_FLAGS', 'L4_DST_PORT', 'L7_PROTO'],\n",
        "        class_column=\"Attack\",\n",
        "        benign_label=\"Benign\"\n",
        "    )\n",
        "\n",
        "from framework.flow_transformer_parameters import FlowTransformerParameters\n",
        "from framework.flow_transformer import FlowTransformer\n",
        "\n",
        "pre_processing = StandardPreProcessing(n_categorical_levels=32)\n",
        "encoding = RecordLevelEmbed(64)\n",
        "transformer = BasicTransformer(n_layers=2, internal_size=128, n_heads=2)\n",
        "classification_head = LastTokenClassificationHead()\n",
        "\n",
        "# Define the transformer\n",
        "ft = FlowTransformer(pre_processing=pre_processing,\n",
        "                     input_encoding=encoding,\n",
        "                     sequential_model=transformer,\n",
        "                     classification_head=classification_head,\n",
        "                     params=FlowTransformerParameters(window_size=8, mlp_layer_sizes=[128], mlp_dropout=0.1))\n",
        "\n",
        "from framework.enumerations import EvaluationDatasetSampling\n",
        "from IPython.display import display\n",
        "\n",
        "# SIAN\n",
        "df = ft.load_dataset(\"UNSW-NB15\",\n",
        "                data_path+datasets[1],\n",
        "                specification=flow_format,\n",
        "                evaluation_dataset_sampling=EvaluationDatasetSampling.LastRows,\n",
        "                evaluation_percent=0.1,\n",
        "                cache_path=demonstration_folder)\n",
        "\n",
        "display(df.iloc[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "DMoRLR7i-VFI",
        "outputId": "e036d62f-5198-4294-e9cd-a5b67231de2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cache file path: demonstration/UNSW-NB15_0_QdLmZHuh8yOmlGcKBEkf7hepImY0_5EjmvToFWKee8t20u0dFpVzNu4s0.feather\n",
            "Reading directly from cache demonstration/UNSW-NB15_0_QdLmZHuh8yOmlGcKBEkf7hepImY0_5EjmvToFWKee8t20u0dFpVzNu4s0.feather...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "     OUT_PKTS  MAX_IP_PKT_LEN  DURATION_IN  RETRANSMITTED_OUT_BYTES   MAX_TTL  \\\n",
              "0    0.148859        0.565324          0.0                 0.000000  0.630549   \n",
              "1    0.223288        0.565324          0.0                 0.284665  0.630549   \n",
              "2    0.266827        0.575948          0.0                 0.326006  0.630549   \n",
              "3    0.297718        0.598516          0.0                 0.353458  0.630549   \n",
              "4    0.331913        0.598516          0.0                 0.384771  0.630549   \n",
              "..        ...             ...          ...                      ...       ...   \n",
              "495  0.349851        0.598516          0.0                 0.395384  0.630549   \n",
              "496  0.223288        0.565324          0.0                 0.284665  0.630549   \n",
              "497  0.365217        0.598516          0.0                 0.405933  0.630549   \n",
              "498  0.266827        0.575948          0.0                 0.326006  0.630549   \n",
              "499  0.297718        0.598516          0.0                 0.353458  0.630549   \n",
              "\n",
              "     RETRANSMITTED_IN_BYTES   IN_PKTS  TCP_WIN_MAX_OUT  RETRANSMITTED_IN_PKTS  \\\n",
              "0                  0.000000  0.000000         0.801390               0.000000   \n",
              "1                  0.261166  0.160324         0.817828               0.074172   \n",
              "2                  0.295819  0.218877         0.831726               0.117560   \n",
              "3                  0.317712  0.255508         0.843766               0.148344   \n",
              "4                  0.334477  0.293311         0.854385               0.172222   \n",
              "..                      ...       ...              ...                    ...   \n",
              "495                0.347007  0.312343         0.863885               0.191732   \n",
              "496                0.261166  0.160324         0.817828               0.074172   \n",
              "497                0.359164  0.328315         0.872479               0.208227   \n",
              "498                0.295819  0.218877         0.831726               0.117560   \n",
              "499                0.317712  0.255508         0.843766               0.148344   \n",
              "\n",
              "     NUM_PKTS_128_TO_256_BYTES  ...  L7_PROTO_23  L7_PROTO_24  L7_PROTO_25  \\\n",
              "0                          0.0  ...        False        False        False   \n",
              "1                          0.0  ...        False        False        False   \n",
              "2                          0.0  ...        False        False        False   \n",
              "3                          0.0  ...        False        False        False   \n",
              "4                          0.0  ...        False        False        False   \n",
              "..                         ...  ...          ...          ...          ...   \n",
              "495                        0.0  ...        False        False        False   \n",
              "496                        0.0  ...        False        False        False   \n",
              "497                        0.0  ...        False        False        False   \n",
              "498                        0.0  ...        False        False        False   \n",
              "499                        0.0  ...        False        False        False   \n",
              "\n",
              "     L7_PROTO_26  L7_PROTO_27  L7_PROTO_28  L7_PROTO_29  L7_PROTO_30  \\\n",
              "0          False        False        False        False        False   \n",
              "1          False        False        False        False        False   \n",
              "2          False        False        False        False        False   \n",
              "3          False        False        False        False        False   \n",
              "4          False        False        False        False        False   \n",
              "..           ...          ...          ...          ...          ...   \n",
              "495        False        False        False        False        False   \n",
              "496        False        False        False        False        False   \n",
              "497        False        False        False        False        False   \n",
              "498        False        False        False        False        False   \n",
              "499        False        False        False        False        False   \n",
              "\n",
              "     L7_PROTO_31  L7_PROTO_32  \n",
              "0          False        False  \n",
              "1          False        False  \n",
              "2          False        False  \n",
              "3          False        False  \n",
              "4          False        False  \n",
              "..           ...          ...  \n",
              "495        False        False  \n",
              "496        False        False  \n",
              "497        False        False  \n",
              "498        False        False  \n",
              "499        False        False  \n",
              "\n",
              "[500 rows x 268 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-afdb93af-ce39-426a-a665-97467b4b2761\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OUT_PKTS</th>\n",
              "      <th>MAX_IP_PKT_LEN</th>\n",
              "      <th>DURATION_IN</th>\n",
              "      <th>RETRANSMITTED_OUT_BYTES</th>\n",
              "      <th>MAX_TTL</th>\n",
              "      <th>RETRANSMITTED_IN_BYTES</th>\n",
              "      <th>IN_PKTS</th>\n",
              "      <th>TCP_WIN_MAX_OUT</th>\n",
              "      <th>RETRANSMITTED_IN_PKTS</th>\n",
              "      <th>NUM_PKTS_128_TO_256_BYTES</th>\n",
              "      <th>...</th>\n",
              "      <th>L7_PROTO_23</th>\n",
              "      <th>L7_PROTO_24</th>\n",
              "      <th>L7_PROTO_25</th>\n",
              "      <th>L7_PROTO_26</th>\n",
              "      <th>L7_PROTO_27</th>\n",
              "      <th>L7_PROTO_28</th>\n",
              "      <th>L7_PROTO_29</th>\n",
              "      <th>L7_PROTO_30</th>\n",
              "      <th>L7_PROTO_31</th>\n",
              "      <th>L7_PROTO_32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.148859</td>\n",
              "      <td>0.565324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.630549</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.801390</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.223288</td>\n",
              "      <td>0.565324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.284665</td>\n",
              "      <td>0.630549</td>\n",
              "      <td>0.261166</td>\n",
              "      <td>0.160324</td>\n",
              "      <td>0.817828</td>\n",
              "      <td>0.074172</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.266827</td>\n",
              "      <td>0.575948</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.326006</td>\n",
              "      <td>0.630549</td>\n",
              "      <td>0.295819</td>\n",
              "      <td>0.218877</td>\n",
              "      <td>0.831726</td>\n",
              "      <td>0.117560</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.297718</td>\n",
              "      <td>0.598516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.353458</td>\n",
              "      <td>0.630549</td>\n",
              "      <td>0.317712</td>\n",
              "      <td>0.255508</td>\n",
              "      <td>0.843766</td>\n",
              "      <td>0.148344</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.331913</td>\n",
              "      <td>0.598516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.384771</td>\n",
              "      <td>0.630549</td>\n",
              "      <td>0.334477</td>\n",
              "      <td>0.293311</td>\n",
              "      <td>0.854385</td>\n",
              "      <td>0.172222</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>0.349851</td>\n",
              "      <td>0.598516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.395384</td>\n",
              "      <td>0.630549</td>\n",
              "      <td>0.347007</td>\n",
              "      <td>0.312343</td>\n",
              "      <td>0.863885</td>\n",
              "      <td>0.191732</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>0.223288</td>\n",
              "      <td>0.565324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.284665</td>\n",
              "      <td>0.630549</td>\n",
              "      <td>0.261166</td>\n",
              "      <td>0.160324</td>\n",
              "      <td>0.817828</td>\n",
              "      <td>0.074172</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>0.365217</td>\n",
              "      <td>0.598516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.405933</td>\n",
              "      <td>0.630549</td>\n",
              "      <td>0.359164</td>\n",
              "      <td>0.328315</td>\n",
              "      <td>0.872479</td>\n",
              "      <td>0.208227</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>0.266827</td>\n",
              "      <td>0.575948</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.326006</td>\n",
              "      <td>0.630549</td>\n",
              "      <td>0.295819</td>\n",
              "      <td>0.218877</td>\n",
              "      <td>0.831726</td>\n",
              "      <td>0.117560</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>0.297718</td>\n",
              "      <td>0.598516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.353458</td>\n",
              "      <td>0.630549</td>\n",
              "      <td>0.317712</td>\n",
              "      <td>0.255508</td>\n",
              "      <td>0.843766</td>\n",
              "      <td>0.148344</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows  268 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afdb93af-ce39-426a-a665-97467b4b2761')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-afdb93af-ce39-426a-a665-97467b4b2761 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-afdb93af-ce39-426a-a665-97467b4b2761');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-928061f2-5490-4386-83df-872395fbbbc7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-928061f2-5490-4386-83df-872395fbbbc7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-928061f2-5490-4386-83df-872395fbbbc7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the transformer model\n",
        "m = ft.build_model()\n",
        "m.summary()\n",
        "\n",
        "# Compile the model\n",
        "m.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=['binary_accuracy'], jit_compile=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jrnUn2-l_ADl",
        "outputId": "97fc8abd-fa2c-41db-e179-a2bf1d457167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " input_OUT_PKTS       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_MAX_IP_PKT_L  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_DURATION_IN    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_MAX_TTL        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_IN_PKTS        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_TCP_WIN_MAX_  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_NUM_PKTS_128  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_IN_BYTES       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_SRC_TO_DST_S  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_LONGEST_FLOW  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_DST_TO_SRC_S  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_NUM_PKTS_UP_  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_SHORTEST_FLO  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_DURATION_OUT   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_SRC_TO_DST_A  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_MIN_TTL        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_OUT_BYTES      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_DST_TO_SRC_A  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_NUM_PKTS_512  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_NUM_PKTS_256  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_TCP_WIN_MAX_  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_NUM_PKTS_102  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_MIN_IP_PKT_L  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_FLOW_DURATIO  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)                \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_CLIENT_TCP_F  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_L4_SRC_PORT    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_TCP_FLAGS      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m17\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_ICMP_IPV4_TY  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_ICMP_TYPE      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_PROTOCOL       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_SERVER_TCP_F  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m15\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_L4_DST_PORT    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " input_L7_PROTO       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)               \u001b[38;5;34m0\u001b[0m  -                 \n",
              " (\u001b[38;5;33mInputLayer\u001b[0m)                                                          \n",
              "\n",
              " feature_concat       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m268\u001b[0m)              \u001b[38;5;34m0\u001b[0m  input_OUT_PKTS[\u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mConcatenate\u001b[0m)                                       input_MAX_IP_PKT \n",
              "                                                     input_DURATION_I \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_MAX_TTL[\u001b[38;5;34m0\u001b[0m] \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_IN_PKTS[\u001b[38;5;34m0\u001b[0m] \n",
              "                                                     input_TCP_WIN_MA \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_NUM_PKTS_1 \n",
              "                                                     input_IN_BYTES[\u001b[38;5;34m0\u001b[0m \n",
              "                                                     input_SRC_TO_DST \n",
              "                                                     input_LONGEST_FL \n",
              "                                                     input_DST_TO_SRC \n",
              "                                                     input_NUM_PKTS_U \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_SHORTEST_F \n",
              "                                                     input_DURATION_O \n",
              "                                                     input_SRC_TO_DST \n",
              "                                                     input_MIN_TTL[\u001b[38;5;34m0\u001b[0m] \n",
              "                                                     input_OUT_BYTES[\u001b[38;5;34m\u001b[0m \n",
              "                                                     input_DST_TO_SRC \n",
              "                                                     input_NUM_PKTS_5 \n",
              "                                                     input_NUM_PKTS_2 \n",
              "                                                     input_TCP_WIN_MA \n",
              "                                                     input_NUM_PKTS_1 \n",
              "                                                     input_MIN_IP_PKT \n",
              "                                                     input_FLOW_DURAT \n",
              "                                                     input_CLIENT_TCP \n",
              "                                                     input_L4_SRC_POR \n",
              "                                                     input_TCP_FLAGS[\u001b[38;5;34m\u001b[0m \n",
              "                                                     input_ICMP_IPV4_ \n",
              "                                                     input_ICMP_TYPE[\u001b[38;5;34m\u001b[0m \n",
              "                                                     input_PROTOCOL[\u001b[38;5;34m0\u001b[0m \n",
              "                                                     input_SERVER_TCP \n",
              "                                                     input_L4_DST_POR \n",
              "                                                     input_L7_PROTO[\u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " embed (\u001b[38;5;33mDense\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m17,216\u001b[0m  feature_concat[\u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " block_0_transforme  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m83,200\u001b[0m  embed[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       \n",
              " (\u001b[38;5;33mTransformerEncode\u001b[0m                                                   \n",
              "\n",
              " block_1_transforme  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)          \u001b[38;5;34m83,200\u001b[0m  block_0_transfor \n",
              " (\u001b[38;5;33mTransformerEncode\u001b[0m                                                   \n",
              "\n",
              " slice_last (\u001b[38;5;33mLambda\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  \u001b[38;5;34m0\u001b[0m  block_1_transfor \n",
              "\n",
              " classification_mlp  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)             \u001b[38;5;34m8,320\u001b[0m  slice_last[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  \n",
              " (\u001b[38;5;33mDense\u001b[0m)                                                               \n",
              "\n",
              " dropout_2 (\u001b[38;5;33mDropout\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 \u001b[38;5;34m0\u001b[0m  classification_m \n",
              "\n",
              " binary_classificat  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 \u001b[38;5;34m129\u001b[0m  dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   \n",
              " (\u001b[38;5;33mDense\u001b[0m)                                                               \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)        </span><span style=\"font-weight: bold\"> Output Shape      </span><span style=\"font-weight: bold\">    Param # </span><span style=\"font-weight: bold\"> Connected to      </span>\n",
              "\n",
              " input_OUT_PKTS       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_MAX_IP_PKT_L  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_DURATION_IN    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_MAX_TTL        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_IN_PKTS        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_TCP_WIN_MAX_  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_NUM_PKTS_128  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_IN_BYTES       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_SRC_TO_DST_S  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_LONGEST_FLOW  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_DST_TO_SRC_S  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_NUM_PKTS_UP_  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_RETRANSMITTE  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_SHORTEST_FLO  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_DURATION_OUT   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_SRC_TO_DST_A  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_MIN_TTL        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_OUT_BYTES      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_DST_TO_SRC_A  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_NUM_PKTS_512  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_NUM_PKTS_256  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_TCP_WIN_MAX_  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_NUM_PKTS_102  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_MIN_IP_PKT_L  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_FLOW_DURATIO  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_CLIENT_TCP_F  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_L4_SRC_PORT    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_TCP_FLAGS      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_ICMP_IPV4_TY  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_ICMP_TYPE      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_PROTOCOL       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_SERVER_TCP_F  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_L4_DST_PORT    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " input_L7_PROTO       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  -                 \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                                                          \n",
              "\n",
              " feature_concat       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">268</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  input_OUT_PKTS[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)                                       input_MAX_IP_PKT \n",
              "                                                     input_DURATION_I \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_MAX_TTL[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_IN_PKTS[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "                                                     input_TCP_WIN_MA \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_NUM_PKTS_1 \n",
              "                                                     input_IN_BYTES[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                                                     input_SRC_TO_DST \n",
              "                                                     input_LONGEST_FL \n",
              "                                                     input_DST_TO_SRC \n",
              "                                                     input_NUM_PKTS_U \n",
              "                                                     input_RETRANSMIT \n",
              "                                                     input_SHORTEST_F \n",
              "                                                     input_DURATION_O \n",
              "                                                     input_SRC_TO_DST \n",
              "                                                     input_MIN_TTL[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] \n",
              "                                                     input_OUT_BYTES[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                                                     input_DST_TO_SRC \n",
              "                                                     input_NUM_PKTS_5 \n",
              "                                                     input_NUM_PKTS_2 \n",
              "                                                     input_TCP_WIN_MA \n",
              "                                                     input_NUM_PKTS_1 \n",
              "                                                     input_MIN_IP_PKT \n",
              "                                                     input_FLOW_DURAT \n",
              "                                                     input_CLIENT_TCP \n",
              "                                                     input_L4_SRC_POR \n",
              "                                                     input_TCP_FLAGS[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                                                     input_ICMP_IPV4_ \n",
              "                                                     input_ICMP_TYPE[<span style=\"color: #00af00; text-decoration-color: #00af00\"></span> \n",
              "                                                     input_PROTOCOL[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "                                                     input_SERVER_TCP \n",
              "                                                     input_L4_DST_POR \n",
              "                                                     input_L7_PROTO[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " embed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">17,216</span>  feature_concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " block_0_transforme  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">83,200</span>  embed[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode</span>                                                   \n",
              "\n",
              " block_1_transforme  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          <span style=\"color: #00af00; text-decoration-color: #00af00\">83,200</span>  block_0_transfor \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode</span>                                                   \n",
              "\n",
              " slice_last (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  block_1_transfor \n",
              "\n",
              " classification_mlp  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span>  slice_last[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                               \n",
              "\n",
              " dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>  classification_m \n",
              "\n",
              " binary_classificat  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>  dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                                                               \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m192,065\u001b[0m (750.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192,065</span> (750.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m192,065\u001b[0m (750.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192,065</span> (750.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_results, eval_results, final_epoch) = ft.evaluate(m, batch_size=128, epochs=5, steps_per_epoch=64, early_stopping_patience=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_R5uFnWG24q",
        "outputId": "4e18878d-0d46-492f-b8b2-87429f14e83c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building eval dataset...\n",
            "Splitting dataset to featurewise...\n",
            "Evaluation dataset is built!\n",
            "Positive samples in eval set: 16271\n",
            "Negative samples in eval set: 222756\n",
            "Epoch = 0 / 5 (early stop in 5), step = 0, loss = 0.73607, results = [array(0.7360732, dtype=float32), array(0.546875, dtype=float32)] -- elapsed (train): 0.00s\n",
            "Epoch = 0 / 5 (early stop in 5), step = 13, loss = 0.36630, results = [array(0.3663045, dtype=float32), array(0.83370537, dtype=float32)] -- elapsed (train): 1.11s\n",
            "Epoch = 0 / 5 (early stop in 5), step = 30, loss = 0.22226, results = [array(0.22226392, dtype=float32), array(0.9080141, dtype=float32)] -- elapsed (train): 2.20s\n",
            "Epoch = 0 / 5 (early stop in 5), step = 46, loss = 0.16748, results = [array(0.16748103, dtype=float32), array(0.9333444, dtype=float32)] -- elapsed (train): 3.32s\n",
            "Epoch = 0 / 5 (early stop in 5), step = 63, loss = 0.13574, results = [array(0.13573794, dtype=float32), array(0.9468994, dtype=float32)] -- elapsed (train): 4.47s\n",
            "Epoch = 1 / 5 (early stop in 5), step = 10, loss = 0.11995, results = [array(0.11994722, dtype=float32), array(0.9535417, dtype=float32)] -- elapsed (train): 5.56s\n",
            "Epoch = 1 / 5 (early stop in 5), step = 28, loss = 0.10382, results = [array(0.10381939, dtype=float32), array(0.9611055, dtype=float32)] -- elapsed (train): 6.65s\n",
            "Epoch = 1 / 5 (early stop in 5), step = 46, loss = 0.09061, results = [array(0.09060854, dtype=float32), array(0.9667793, dtype=float32)] -- elapsed (train): 7.74s\n",
            "Epoch = 2 / 5 (early stop in 5), step = 0, loss = 0.08453, results = [array(0.0845296, dtype=float32), array(0.96990067, dtype=float32)] -- elapsed (train): 8.85s\n",
            "Epoch = 2 / 5 (early stop in 5), step = 12, loss = 0.08075, results = [array(0.08075459, dtype=float32), array(0.9716866, dtype=float32)] -- elapsed (train): 9.93s\n",
            "Epoch = 2 / 5 (early stop in 5), step = 27, loss = 0.07563, results = [array(0.07563154, dtype=float32), array(0.97365785, dtype=float32)] -- elapsed (train): 10.98s\n",
            "Epoch = 2 / 5 (early stop in 5), step = 45, loss = 0.07113, results = [array(0.07112722, dtype=float32), array(0.9757543, dtype=float32)] -- elapsed (train): 12.11s\n",
            "Epoch = 2 / 5 (early stop in 5), step = 63, loss = 0.06678, results = [array(0.06677627, dtype=float32), array(0.9775798, dtype=float32)] -- elapsed (train): 13.20s\n",
            "Epoch = 3 / 5 (early stop in 5), step = 14, loss = 0.06404, results = [array(0.06404318, dtype=float32), array(0.978827, dtype=float32)] -- elapsed (train): 14.31s\n",
            "Epoch = 3 / 5 (early stop in 5), step = 27, loss = 0.06132, results = [array(0.06131943, dtype=float32), array(0.97982955, dtype=float32)] -- elapsed (train): 15.41s\n",
            "Epoch = 3 / 5 (early stop in 5), step = 45, loss = 0.05929, results = [array(0.05929158, dtype=float32), array(0.9808627, dtype=float32)] -- elapsed (train): 16.54s\n",
            "Epoch = 3 / 5 (early stop in 5), step = 63, loss = 0.05785, results = [array(0.05784529, dtype=float32), array(0.9816284, dtype=float32)] -- elapsed (train): 17.63s\n",
            "Epoch = 4 / 5 (early stop in 5), step = 16, loss = 0.05625, results = [array(0.05625252, dtype=float32), array(0.9822573, dtype=float32)] -- elapsed (train): 18.72s\n",
            "Epoch = 4 / 5 (early stop in 5), step = 27, loss = 0.05477, results = [array(0.05477137, dtype=float32), array(0.982807, dtype=float32)] -- elapsed (train): 19.82s\n",
            "Epoch = 4 / 5 (early stop in 5), step = 45, loss = 0.05296, results = [array(0.0529579, dtype=float32), array(0.9835731, dtype=float32)] -- elapsed (train): 20.94s\n",
            "Epoch = 4 / 5 (early stop in 5), step = 63, loss = 0.05110, results = [array(0.05109804, dtype=float32), array(0.9842041, dtype=float32)] -- elapsed (train): 22.04s\n",
            "\u001b[1m7470/7470\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 9ms/step\n",
            "Epoch 4 yielded predictions: (239027,), overall balanced accuracy: 99.36%, TP = 16,232 / 16,271, TN = 220,422 / 222,756\n"
          ]
        }
      ]
    }
  ]
}